{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# data = h5py.File('/home/sunji/ANN/glove_200_angular/glove-200-angular.hdf5', 'r')\n",
    "# data_train = np.array(data['train'])\n",
    "# data_test = np.array(data['test'])\n",
    "# with open('/home/sunji/ANN/glove_200_angular/clusters_glove_200_angular.pkl', 'rb') as f:\n",
    "#     clusters = pickle.load(f)\n",
    "# with open('/home/sunji/ANN/glove_200_angular/ground_truth_glove_200_angular_0_4_0_5.pkl', 'rb') as f:\n",
    "#     ground_truth_total = pickle.load(f)\n",
    "\n",
    "# data = h5py.File('/home/sunji/ANN/fashion_mnist_784_euclidean/fashion-mnist-784-euclidean.hdf5', 'r')\n",
    "# data_train = np.array(data['train'])\n",
    "# data_test = np.array(data['test'])\n",
    "# with open('/home/sunji/ANN/fashion_mnist_784_euclidean/clusters_fashion_mnist_784_euclidean.pkl', 'rb') as f:\n",
    "#     clusters = pickle.load(f)\n",
    "# with open('/home/sunji/ANN/fashion_mnist_784_euclidean/ground_truth_fashion_mnist_784_euclidean_0_0_0_5.pkl', 'rb') as f:\n",
    "#     ground_truth_total = pickle.load(f)\n",
    "    \n",
    "# data = h5py.File('/home/sunji/ANN/nytimes_256_angular/nytimes-256-angular.hdf5', 'r')\n",
    "# data_train = np.array(data['train'])\n",
    "# data_test = np.array(data['test'])\n",
    "# with open('/home/sunji/ANN/nytimes_256_angular/clusters_nytimes_256_angular.pkl', 'rb') as f:\n",
    "#     clusters = pickle.load(f)\n",
    "# with open('/home/sunji/ANN/nytimes_256_angular/ground_truth_nytimes_256_angular_0_4_0_5.pkl', 'rb') as f:\n",
    "#     ground_truth_total = pickle.load(f)\n",
    "    \n",
    "# data = h5py.File('/home/sunji/ANN/sift_128_euclidean/sift-128-euclidean.hdf5', 'r')\n",
    "# data_train = np.array(data['train'])\n",
    "# data_test = np.array(data['test'])\n",
    "# with open('/home/sunji/ANN/sift_128_euclidean/clusters_sift_128_euclidean.pkl', 'rb') as f:\n",
    "#     clusters = pickle.load(f)\n",
    "# with open('/home/sunji/ANN/sift_128_euclidean/ground_truth_sift_128_euclidean_0_0_0_2.pkl', 'rb') as f:\n",
    "#     ground_truth_total = pickle.load(f)\n",
    "\n",
    "# data = h5py.File('/home/sunji/ANN/kosarak_jaccard/kosarak-jaccard.hdf5', 'r')\n",
    "# data_train = np.array(data['train'])\n",
    "# data_test = np.array(data['test'])\n",
    "# with open('/home/sunji/ANN/kosarak_jaccard/clusters_kosarak_jaccard.pkl', 'rb') as f:\n",
    "#     clusters = pickle.load(f)\n",
    "# with open('/home/sunji/ANN/kosarak_jaccard/ground_truth_kosarak_jaccard_0_9_1_0.pkl', 'rb') as f:\n",
    "#     ground_truth_total = pickle.load(f)\n",
    "    \n",
    "data = h5py.File('/home/sunji/ANN/gist_960_euclidean/gist-960-euclidean.hdf5', 'r')\n",
    "data_train = np.array(data['train'])\n",
    "data_test = np.array(data['test'])\n",
    "with open('/home/sunji/ANN/gist_960_euclidean/clusters_gist_960_euclidean.pkl', 'rb') as f:\n",
    "    clusters = pickle.load(f)\n",
    "with open('/home/sunji/ANN/gist_960_euclidean/ground_truth_gist_960_euclidean_0_0_0_1.pkl', 'rb') as f:\n",
    "    ground_truth_total = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from scipy import spatial\n",
    "\n",
    "def euclidean_dist_normalized(x1, x2=None, eps=1e-8):\n",
    "    if np.isnan(x2):\n",
    "        return 1.0\n",
    "    left = x1\n",
    "    right = x2\n",
    "    return np.sqrt(((left - right) ** 2).mean())\n",
    "\n",
    "def angular_dist(x1, x2=None, eps=1e-8):\n",
    "    cosine_sim = 1 - spatial.distance.cosine(x1, x2)\n",
    "#     print (cosine_sim)\n",
    "    distance = np.arccos(cosine_sim) / 3.14159267\n",
    "    return distance\n",
    "\n",
    "def jaccard(x1, x2=None, eps=1e-8):\n",
    "    x1 = x1.astype(bool)\n",
    "    x2 = x2.astype(bool)\n",
    "    return 1.0 - np.double(np.bitwise_and(x1, x2).sum()) / np.double(np.bitwise_or(x1, x2).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster_size = len(clusters)\n",
    "# query_size = 10000\n",
    "# min_threshold = 0.4\n",
    "# max_threshold = 0.5\n",
    "# slot = 0.002\n",
    "# queries_dimension = 200\n",
    "# normalize_factor = 1.0\n",
    "# distance_function = angular_dist\n",
    "# hidden_num = 128\n",
    "# output_num = cluster_size\n",
    "# dataset_id = 'glove_200_angular'\n",
    "\n",
    "# cluster_size = len(clusters)\n",
    "# query_size = 10000\n",
    "# min_threshold = 0.0\n",
    "# max_threshold = 0.5\n",
    "# slot = 0.01\n",
    "# queries_dimension = 784\n",
    "# normalize_factor = 255.0\n",
    "# distance_function = euclidean_dist_normalized\n",
    "# hidden_num = 128\n",
    "# output_num = cluster_size\n",
    "# dataset_id = 'fashion_mnist_784_euclidean'\n",
    "\n",
    "# cluster_size = len(clusters)\n",
    "# query_size = 10000\n",
    "# min_threshold = 0.4\n",
    "# max_threshold = 0.5\n",
    "# slot = 0.002\n",
    "# queries_dimension = 256\n",
    "# normalize_factor = 1.0\n",
    "# distance_function = angular_dist\n",
    "# hidden_num = 128\n",
    "# output_num = cluster_size\n",
    "# dataset_id = 'nytimes_256_angular'\n",
    "\n",
    "# cluster_size = len(clusters)\n",
    "# query_size = 10000\n",
    "# min_threshold = 0.0\n",
    "# max_threshold = 0.2\n",
    "# slot = 0.004\n",
    "# queries_dimension = 128\n",
    "# normalize_factor = 218.0\n",
    "# distance_function = euclidean_dist_normalized\n",
    "# hidden_num = 128\n",
    "# output_num = cluster_size\n",
    "# dataset_id = 'sift_128_euclidean'\n",
    "\n",
    "\n",
    "# cluster_size = len(clusters)\n",
    "# query_size = 500\n",
    "# min_threshold = 0.9\n",
    "# max_threshold = 1.0\n",
    "# slot = 0.002\n",
    "# queries_dimension = 27983\n",
    "# normalize_factor = 1.0\n",
    "# distance_function = jaccard\n",
    "# hidden_num = 128\n",
    "# output_num = cluster_size\n",
    "# dataset_id = 'kosarak_jaccard'\n",
    "\n",
    "cluster_size = len(clusters)\n",
    "query_size = 1000\n",
    "min_threshold = 0.0\n",
    "max_threshold = 0.1\n",
    "slot = 0.001\n",
    "queries_dimension = 960\n",
    "normalize_factor = 1.0\n",
    "distance_function = euclidean_dist_normalized\n",
    "hidden_num = 128\n",
    "output_num = cluster_size\n",
    "dataset_id = 'gist_960_euclidean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_total_level = [[[] for _ in range(query_size)] for _ in range(cluster_size)]\n",
    "for clus in range(cluster_size):\n",
    "    for t in ground_truth_total[clus]:\n",
    "        ground_truth_total_level[t[0]][t[1]].append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = []\n",
    "for cluster in clusters:\n",
    "    centroids.append(np.mean(cluster, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from scipy import spatial\n",
    "import random\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def prepare_for_cluster(cluster_id):\n",
    "    batch_size = 128\n",
    "    \n",
    "    mini = 9999999999\n",
    "    maxi = 0\n",
    "    \n",
    "    train_queries = []\n",
    "    train_thresholds = []\n",
    "    train_targets = []\n",
    "    train_masks = []\n",
    "    for train_id in range(50):\n",
    "#         join_size = int(random.random() * 99 + 1)\n",
    "        join_size = 100\n",
    "        query_ids = np.random.choice(int(query_size * 0.8), join_size, replace=False)\n",
    "        query_ids = np.pad(query_ids, (0, 100-join_size), mode='constant')\n",
    "#         print (query_ids.size)\n",
    "        train_mask = [[1] for _ in range(join_size)] + [[0] for _ in range(100-join_size)]\n",
    "#         queries = []\n",
    "#         for query_id in query_ids:\n",
    "#             queries.append(data_test[query_id]/255.0)\n",
    "        cardinality = 0\n",
    "        for threshold_id, threshold in enumerate(np.arange(min_threshold, max_threshold, slot)):\n",
    "            for query_id_idx in range(join_size):\n",
    "                cardinality += ground_truth_total_level[cluster_id][query_ids[query_id_idx]][threshold_id][-1]\n",
    "            if cardinality > 0:\n",
    "                train_queries.append(query_ids)\n",
    "                train_thresholds.append([threshold+slot])\n",
    "                train_targets.append([cardinality])\n",
    "                train_masks.append(train_mask)\n",
    "                log_c = np.log(cardinality)\n",
    "                if log_c < mini:\n",
    "                    mini = log_c\n",
    "                if log_c > maxi:\n",
    "                    maxi = log_c\n",
    "\n",
    "    test_queries = []\n",
    "    test_thresholds = []\n",
    "    test_targets = []\n",
    "    test_masks = []\n",
    "    for test_id in range(20):\n",
    "#         join_size = int(random.random() * 199 + 1)\n",
    "        join_size = 100\n",
    "        query_ids = np.random.choice(int(query_size * 0.2), join_size, replace=True) + int(query_size * 0.8)\n",
    "        query_ids = np.pad(query_ids, (0, 100-join_size), mode='constant')\n",
    "        test_mask = [[1] for _ in range(join_size)] + [[0] for _ in range(100-join_size)]\n",
    "        cardinality = 0\n",
    "#         queries = []\n",
    "#         for query_id in query_ids:\n",
    "#             queries.append(data_test[query_id]/255.0)\n",
    "        for threshold_id, threshold in enumerate(np.arange(min_threshold, max_threshold, slot)):\n",
    "            for query_id_idx in range(join_size):\n",
    "                cardinality += ground_truth_total_level[cluster_id][query_ids[query_id_idx]][threshold_id][-1]\n",
    "            if cardinality > 0:\n",
    "                test_queries.append(query_ids)\n",
    "                test_thresholds.append([threshold+slot])\n",
    "                test_targets.append([cardinality])\n",
    "                test_masks.append(test_mask)\n",
    "                log_c = np.log(cardinality)\n",
    "                if log_c < mini:\n",
    "                    mini = log_c\n",
    "                if log_c > maxi:\n",
    "                    maxi = log_c\n",
    "                \n",
    "    print (torch.FloatTensor(train_queries).shape, torch.FloatTensor(test_queries).shape)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        torch.utils.data.TensorDataset(torch.FloatTensor(train_masks), torch.FloatTensor(train_queries), torch.FloatTensor(train_thresholds), torch.FloatTensor(train_targets)), batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        torch.utils.data.TensorDataset(torch.FloatTensor(test_masks), torch.FloatTensor(test_queries), torch.FloatTensor(test_thresholds), torch.FloatTensor(test_targets)), batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    return train_loader, test_loader, mini, maxi\n",
    "#     return None, test_loader, 0.0, 0.0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([3900, 100]) torch.Size([1352, 100])\n",
      "1\n",
      "torch.Size([4125, 100]) torch.Size([1487, 100])\n",
      "2\n",
      "torch.Size([3925, 100]) torch.Size([1537, 100])\n",
      "3\n",
      "torch.Size([2574, 100]) torch.Size([1029, 100])\n",
      "4\n",
      "torch.Size([3008, 100]) torch.Size([1215, 100])\n",
      "5\n",
      "torch.Size([3641, 100]) torch.Size([1449, 100])\n",
      "6\n",
      "torch.Size([1555, 100]) torch.Size([692, 100])\n",
      "7\n",
      "torch.Size([3932, 100]) torch.Size([1391, 100])\n",
      "8\n",
      "torch.Size([3738, 100]) torch.Size([1479, 100])\n",
      "9\n",
      "torch.Size([4483, 100]) torch.Size([1715, 100])\n",
      "10\n",
      "torch.Size([3229, 100]) torch.Size([1412, 100])\n",
      "11\n",
      "torch.Size([3570, 100]) torch.Size([1323, 100])\n",
      "12\n",
      "torch.Size([2856, 100]) torch.Size([1078, 100])\n",
      "13\n",
      "torch.Size([3147, 100]) torch.Size([1262, 100])\n",
      "14\n",
      "torch.Size([3331, 100]) torch.Size([1231, 100])\n",
      "15\n",
      "torch.Size([2584, 100]) torch.Size([1050, 100])\n",
      "16\n",
      "torch.Size([3761, 100]) torch.Size([1661, 100])\n",
      "17\n",
      "torch.Size([2826, 100]) torch.Size([1017, 100])\n",
      "18\n",
      "torch.Size([3082, 100]) torch.Size([1197, 100])\n",
      "19\n",
      "torch.Size([3176, 100]) torch.Size([1264, 100])\n",
      "20\n",
      "torch.Size([2776, 100]) torch.Size([1144, 100])\n",
      "21\n",
      "torch.Size([4105, 100]) torch.Size([1419, 100])\n",
      "22\n",
      "torch.Size([4077, 100]) torch.Size([1554, 100])\n",
      "23\n",
      "torch.Size([4369, 100]) torch.Size([1624, 100])\n",
      "24\n",
      "torch.Size([3315, 100]) torch.Size([1267, 100])\n",
      "25\n",
      "torch.Size([3913, 100]) torch.Size([1412, 100])\n",
      "26\n",
      "torch.Size([3583, 100]) torch.Size([1528, 100])\n",
      "27\n",
      "torch.Size([2991, 100]) torch.Size([1160, 100])\n",
      "28\n",
      "torch.Size([2184, 100]) torch.Size([884, 100])\n",
      "29\n",
      "torch.Size([2271, 100]) torch.Size([922, 100])\n",
      "30\n",
      "torch.Size([3407, 100]) torch.Size([1332, 100])\n",
      "31\n",
      "torch.Size([3792, 100]) torch.Size([1663, 100])\n",
      "32\n",
      "torch.Size([2635, 100]) torch.Size([1011, 100])\n",
      "33\n",
      "torch.Size([3220, 100]) torch.Size([1281, 100])\n",
      "34\n",
      "torch.Size([2417, 100]) torch.Size([1469, 100])\n",
      "35\n",
      "torch.Size([2749, 100]) torch.Size([1092, 100])\n",
      "36\n",
      "torch.Size([3035, 100]) torch.Size([1215, 100])\n",
      "37\n",
      "torch.Size([3134, 100]) torch.Size([1244, 100])\n",
      "38\n",
      "torch.Size([3388, 100]) torch.Size([1314, 100])\n",
      "39\n",
      "torch.Size([3185, 100]) torch.Size([1295, 100])\n",
      "40\n",
      "torch.Size([1972, 100]) torch.Size([789, 100])\n",
      "41\n",
      "torch.Size([3996, 100]) torch.Size([1581, 100])\n",
      "42\n",
      "torch.Size([3358, 100]) torch.Size([1343, 100])\n",
      "43\n",
      "torch.Size([3046, 100]) torch.Size([1257, 100])\n",
      "44\n",
      "torch.Size([3298, 100]) torch.Size([1204, 100])\n",
      "45\n",
      "torch.Size([3457, 100]) torch.Size([1406, 100])\n",
      "46\n",
      "torch.Size([3645, 100]) torch.Size([1457, 100])\n",
      "47\n",
      "torch.Size([3550, 100]) torch.Size([1435, 100])\n",
      "48\n",
      "torch.Size([4116, 100]) torch.Size([1590, 100])\n",
      "49\n",
      "torch.Size([4341, 100]) torch.Size([1666, 100])\n",
      "50\n",
      "torch.Size([2641, 100]) torch.Size([1214, 100])\n",
      "51\n",
      "torch.Size([3013, 100]) torch.Size([1156, 100])\n",
      "52\n",
      "torch.Size([4060, 100]) torch.Size([1568, 100])\n",
      "53\n",
      "torch.Size([3965, 100]) torch.Size([1542, 100])\n",
      "54\n",
      "torch.Size([3906, 100]) torch.Size([1553, 100])\n",
      "55\n",
      "torch.Size([2712, 100]) torch.Size([1060, 100])\n",
      "56\n",
      "torch.Size([3601, 100]) torch.Size([1380, 100])\n",
      "57\n",
      "torch.Size([3572, 100]) torch.Size([1304, 100])\n",
      "58\n",
      "torch.Size([3336, 100]) torch.Size([1341, 100])\n",
      "59\n",
      "torch.Size([3519, 100]) torch.Size([1397, 100])\n",
      "60\n",
      "torch.Size([4275, 100]) torch.Size([1633, 100])\n",
      "61\n",
      "torch.Size([3348, 100]) torch.Size([1288, 100])\n",
      "62\n",
      "torch.Size([3947, 100]) torch.Size([1563, 100])\n",
      "63\n",
      "torch.Size([3243, 100]) torch.Size([1452, 100])\n",
      "64\n",
      "torch.Size([3419, 100]) torch.Size([1310, 100])\n",
      "65\n",
      "torch.Size([3575, 100]) torch.Size([1345, 100])\n",
      "66\n",
      "torch.Size([2942, 100]) torch.Size([1202, 100])\n",
      "67\n",
      "torch.Size([2974, 100]) torch.Size([1190, 100])\n",
      "68\n",
      "torch.Size([3312, 100]) torch.Size([1304, 100])\n",
      "69\n",
      "torch.Size([3696, 100]) torch.Size([1453, 100])\n",
      "70\n",
      "torch.Size([2379, 100]) torch.Size([861, 100])\n",
      "71\n",
      "torch.Size([3080, 100]) torch.Size([1252, 100])\n",
      "72\n",
      "torch.Size([3353, 100]) torch.Size([1389, 100])\n",
      "73\n",
      "torch.Size([2844, 100]) torch.Size([1101, 100])\n",
      "74\n",
      "torch.Size([3872, 100]) torch.Size([1403, 100])\n",
      "75\n",
      "torch.Size([3506, 100]) torch.Size([1419, 100])\n",
      "76\n",
      "torch.Size([3147, 100]) torch.Size([1258, 100])\n",
      "77\n",
      "torch.Size([4428, 100]) torch.Size([1725, 100])\n",
      "78\n",
      "torch.Size([3404, 100]) torch.Size([1334, 100])\n",
      "79\n",
      "torch.Size([3519, 100]) torch.Size([1602, 100])\n",
      "80\n",
      "torch.Size([4188, 100]) torch.Size([1605, 100])\n",
      "81\n",
      "torch.Size([3513, 100]) torch.Size([1310, 100])\n",
      "82\n",
      "torch.Size([2236, 100]) torch.Size([939, 100])\n",
      "83\n",
      "torch.Size([4002, 100]) torch.Size([1514, 100])\n",
      "84\n",
      "torch.Size([2597, 100]) torch.Size([1005, 100])\n",
      "85\n",
      "torch.Size([3365, 100]) torch.Size([1350, 100])\n",
      "86\n",
      "torch.Size([3340, 100]) torch.Size([1370, 100])\n",
      "87\n",
      "torch.Size([3511, 100]) torch.Size([1400, 100])\n",
      "88\n",
      "torch.Size([3550, 100]) torch.Size([1382, 100])\n",
      "89\n",
      "torch.Size([3991, 100]) torch.Size([1575, 100])\n",
      "90\n",
      "torch.Size([4415, 100]) torch.Size([1693, 100])\n",
      "91\n",
      "torch.Size([3880, 100]) torch.Size([1707, 100])\n",
      "92\n",
      "torch.Size([2985, 100]) torch.Size([1202, 100])\n",
      "93\n",
      "torch.Size([2788, 100]) torch.Size([1074, 100])\n",
      "94\n",
      "torch.Size([2976, 100]) torch.Size([1161, 100])\n",
      "95\n",
      "torch.Size([3633, 100]) torch.Size([1457, 100])\n",
      "96\n",
      "torch.Size([3403, 100]) torch.Size([1389, 100])\n",
      "97\n",
      "torch.Size([3413, 100]) torch.Size([1264, 100])\n",
      "98\n",
      "torch.Size([3256, 100]) torch.Size([1312, 100])\n",
      "99\n",
      "torch.Size([3559, 100]) torch.Size([1399, 100])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "\n",
    "train_loaders = []\n",
    "test_loaders = []\n",
    "\n",
    "minis = []\n",
    "maxis = []\n",
    "\n",
    "for cluster_id in range(cluster_size):\n",
    "    print (cluster_id)\n",
    "    train, test, mini, maxi = prepare_for_cluster(cluster_id)\n",
    "    train_loaders.append(train)\n",
    "    test_loaders.append(test)\n",
    "    minis.append(mini)\n",
    "    maxis.append(maxi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(labels, mini, maxi):\n",
    "    return (torch.log(labels) - mini) / (maxi - mini)\n",
    "\n",
    "def unnormalize(labels, mini, maxi):\n",
    "    return torch.exp(labels * (maxi - mini) + mini)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BaseLine Local Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "hidden_num = 128\n",
    "\n",
    "class Test_Model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Test_Model, self).__init__()\n",
    "        self.threshold1 = nn.Linear(1, hidden_num)\n",
    "        self.threshold2 = nn.Linear(hidden_num, 1)\n",
    "\n",
    "        self.cnn_layer1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 8, kernel_size=3, stride=1, padding=2), \n",
    "            nn.BatchNorm1d(8),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.AvgPool1d(kernel_size=3, stride=3))\n",
    "        \n",
    "        self.cnn_layer2 = nn.Sequential(\n",
    "            nn.Conv1d(8, 16, kernel_size=3, stride=1, padding=2), \n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.AvgPool1d(kernel_size=3, stride=3))\n",
    "        \n",
    "        self.out1 = nn.Linear(368, hidden_num)\n",
    "        self.out2 = nn.Linear(hidden_num, 1)\n",
    "        \n",
    "    def forward(self, query, threshold):\n",
    "        \n",
    "        query = query.unsqueeze(2).permute(0,2,1)\n",
    "#         print (query.shape)\n",
    "        threshold = F.relu(self.threshold1(threshold))\n",
    "        threshold = self.threshold2(threshold)\n",
    "#         print (threshold.shape)\n",
    "        query = self.cnn_layer1(query)\n",
    "        query = self.cnn_layer2(query)\n",
    "        query = query.view(query.shape[0], -1)\n",
    "#         print (query.shape)\n",
    "        query = self.out1(query)\n",
    "        \n",
    "        output = self.out2(F.relu(query+threshold))\n",
    "        \n",
    "        return output\n",
    "\n",
    "def begin_test_model():\n",
    "#     models = []\n",
    "#     errors = []\n",
    "#     for idx in range(100):\n",
    "    idx = 0\n",
    "    print ('idx: {}'.format(idx))\n",
    "    train = train_loaders[idx]\n",
    "    test = test_loaders[idx]\n",
    "#     mini = min_cards[idx]\n",
    "#     maxi = max_cards[idx]\n",
    "    episode = 5\n",
    "    queries_dimension = 128\n",
    "    model = Test_Model()\n",
    "    opt = optim.Adam(model.parameters(), lr=0.01)\n",
    "    error = test_model(model, opt, train, test, episode)\n",
    "    models.append(model)\n",
    "    errors.append(error)\n",
    "\n",
    "def test_model(model, opt, train, test, episode):\n",
    "    print ('size: {}'.format(len(train)))\n",
    "    test_errors = []\n",
    "    for e in range(episode):\n",
    "        model.train()\n",
    "        for batch_idx, (queries, _, thresholds, targets) in enumerate(train):\n",
    "    #         print (torch.cat((queries, thresholds), 1)[0])\n",
    "            queries = Variable(queries)\n",
    "            thresholds = Variable(thresholds)\n",
    "            targets = Variable(targets)\n",
    "    #         print (targets)\n",
    "            opt.zero_grad()\n",
    "            \n",
    "            estimates = model(queries, thresholds)\n",
    "            \n",
    "            loss = l1_loss(estimates, targets)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "#             if batch_idx % 100 == 0:\n",
    "#                 print('Training: Iteration {0}, Batch {1}, Loss {2}'.format(e, batch_idx, loss.item()))\n",
    "#                 print(model.cnn_layer1[0].weight)\n",
    "            for p in model.parameters():\n",
    "                p.data.clamp_(-2, 2)\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        mse_error = 0.0\n",
    "        q_mean = 0.0\n",
    "        q_max = 0.0\n",
    "        for batch_idx, (queries, _, thresholds, targets) in enumerate(test):\n",
    "            queries = Variable(queries)\n",
    "            thresholds = Variable(thresholds)\n",
    "            targets = Variable(targets)\n",
    "            \n",
    "            estimates = model(queries, thresholds)\n",
    "            \n",
    "            loss = l1_loss(estimates, targets)\n",
    "            mse, qer_mean, qer_max = print_loss(estimates, targets)\n",
    "            test_loss += loss.item()\n",
    "            mse_error += mse.item()\n",
    "            q_mean += qer_mean\n",
    "            if qer_max > q_max:\n",
    "                q_max = qer_max\n",
    "        test_loss /= len(test)\n",
    "        mse_error /= len(test)\n",
    "        q_mean /= len(test)\n",
    "        test_errors.append(q_mean)\n",
    "        print ('Testing: Iteration {0}, Loss {1}, MSE_error {2}, Q_error_mean {3}, Q_error_max {4}'.format(e, test_loss, mse_error, q_mean, q_max))\n",
    "    return np.mean(test_errors[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "begin_test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# queries_dimension = 200\n",
    "# hidden_num = 128\n",
    "\n",
    "class Threshold_Model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Threshold_Model, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, hidden_num)\n",
    "        self.fc2 = nn.Linear(hidden_num, 1)\n",
    "    \n",
    "    def forward(self, threshold):\n",
    "        t1 = F.relu(self.fc1(threshold))\n",
    "        t2 = self.fc2(t1)\n",
    "        return t2\n",
    "\n",
    "class MLP_Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, queries_dimension):\n",
    "        super(MLP_Model, self).__init__()\n",
    "        self.layer1 = nn.Linear(queries_dimension, hidden_num)\n",
    "        self.layer2 = nn.Linear(hidden_num, hidden_num)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        hid = F.relu(self.layer1(inputs))\n",
    "        hid = F.relu(self.layer2(hid))\n",
    "        return hid\n",
    "    \n",
    "class CNN_Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channel, out_channel, kernel_size, stride, padding, pool_type, pool_size):\n",
    "        super(CNN_Model, self).__init__()\n",
    "        if pool_type == 0:\n",
    "            pool_layer = nn.MaxPool1d(kernel_size=pool_size, stride=pool_size)\n",
    "        elif pool_type == 1:\n",
    "            pool_layer = nn.AvgPool1d(kernel_size=pool_size, stride=pool_size)\n",
    "        else:\n",
    "            print ('CNN_Model Init Error, invalid pool_type {}'.format(pool_type))\n",
    "            return\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv1d(in_channel, out_channel, kernel_size=kernel_size, stride=stride, padding=padding), \n",
    "            nn.BatchNorm1d(out_channel),\n",
    "            nn.ReLU(),\n",
    "            pool_layer)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        hid = self.layer(inputs)\n",
    "#         print (hid.shape)\n",
    "#         hid = F.relu(self.n3(hid))\n",
    "#         hid = F.relu(self.n4(hid))\n",
    "#         hid = self.norm2(hid)\n",
    "#         print (hid.shape)\n",
    "#         out2 = self.fc(hid.view(out1.shape[0], -1))\n",
    "        return hid\n",
    "\n",
    "class Output_Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, inputs_dim):\n",
    "        super(Output_Model, self).__init__()\n",
    "        self.fc1 = nn.Linear(inputs_dim, hidden_num)\n",
    "        self.fc2 = nn.Linear(hidden_num, 1)\n",
    "        \n",
    "    def forward(self, queries, threshold):\n",
    "        out1 = F.relu(self.fc1(queries))\n",
    "        out2 = out1 + threshold\n",
    "#         print ('out2: {0}, threshold: {1}'.format(out2.shape, threshold.shape))\n",
    "        out3 = self.fc2(out2)\n",
    "        return out3\n",
    "    \n",
    "# class Set_CNN(nn.Module):\n",
    "    \n",
    "#     def __init__(self, inputs_dim):\n",
    "#         super(Set_CNN, self).__init__()\n",
    "#         self.fc1 = nn.Linear(inputs_dim, hidden_num)\n",
    "#         self.fc2 = nn.Linear(hidden_num, inputs_dim)\n",
    "        \n",
    "#     def forward(self, queries, masks):\n",
    "#         batch_size = queries.shape[0]\n",
    "#         join_size = queries.shape[1]\n",
    "#         queries = queries.view(batch_size * join_size, -1)\n",
    "#         hid = F.relu(self.fc1(queries))\n",
    "#         hid = F.relu(self.fc2(hid))\n",
    "#         hid = (hid.view(batch_size, join_size, -1) * masks).sum(dim=1)\n",
    "#         return hid\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.nn1 = nn.Linear(queries_dimension+1, hidden_num)\n",
    "        self.n1 = nn.Linear(hidden_num, hidden_num)\n",
    "        self.n2 = nn.Linear(hidden_num, hidden_num)\n",
    "#         self.n3 = nn.Linear(hidden_num, hidden_num)\n",
    "#         self.n4 = nn.Linear(hidden_num, hidden_num)\n",
    "        self.nn2 = nn.Linear(hidden_num, 1)\n",
    "        \n",
    "    def forward(self, queries, threshold):\n",
    "        out1 = F.relu(self.nn1(torch.cat([queries, threshold],1)))\n",
    "        hid = out1\n",
    "        hid = F.relu(self.n1(hid))\n",
    "        hid = F.relu(self.n2(hid))\n",
    "#         hid = F.relu(self.n3(hid))\n",
    "#         hid = F.relu(self.n4(hid))\n",
    "#         hid = self.norm2(hid)\n",
    "        out2 = self.nn2(hid)\n",
    "        return out2\n",
    "\n",
    "def loss_fn(estimates, targets, mini, maxi):\n",
    "    est = unnormalize(estimates, mini, maxi)\n",
    "    print (torch.cat((est, targets), 1))\n",
    "    return F.mse_loss(est, targets)\n",
    "\n",
    "def l1_loss(estimates, targets, eps=1e-5):\n",
    "    estimates = torch.exp(estimates)\n",
    "#     torch.pow(10, estimates)\n",
    "    qerror = 0.0\n",
    "    for i in range(estimates.shape[0]):\n",
    "        if estimates[i] > targets[i] + 0.1:\n",
    "            qerror += ((estimates[i] / (targets[i] + 0.1)))\n",
    "        else:\n",
    "            qerror += (((targets[i] + 0.1) / estimates[i]))\n",
    "    return qerror / estimates.shape[0]\n",
    "\n",
    "def mse_loss(estimates, targets, eps=1e-5):\n",
    "#     print (torch.cat((estimates, targets), 1))\n",
    "    return F.mse_loss(estimates, torch.log(targets))\n",
    "\n",
    "def qerror_loss(preds, targets, mini, maxi):\n",
    "    qerror = []\n",
    "    preds = unnormal1ize_label(preds, mini, maxi)\n",
    "#     print (torch.cat((preds, targets), 1))\n",
    "    for i in range(len(targets)):\n",
    "        if (preds[i] > targets[i]).cpu().data.numpy()[0]:\n",
    "            qerror.append(preds[i]/targets[i])\n",
    "        else:\n",
    "            qerror.append(targets[i]/(preds[i] + 0.1))\n",
    "    return torch.mean(torch.cat(qerror) ** 2)\n",
    "\n",
    "def print_loss(estimates, targets):\n",
    "    esti = torch.exp(estimates)\n",
    "#     print (torch.cat((estimates, esti, targets), 1))\n",
    "    qerror = []\n",
    "    for i in range(esti.shape[0]):\n",
    "        if esti[i] > targets[i] + 0.1:\n",
    "            qerror.append((esti[i] / (targets[i] + 0.1)).item())\n",
    "        else:\n",
    "            qerror.append(((targets[i] + 0.1) / esti[i]).item())\n",
    "    \n",
    "    return F.mse_loss(esti, targets), np.mean(qerror), np.max(qerror)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameters Selection Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "\n",
    "def repair_specific_local_model(errors, next_cnn_parameterss, next_cnn_modelss, next_output_models, threshold_models, cluster_id):\n",
    "    clus = cluster_id\n",
    "    print ('Begin Cluster: {}'.format(clus))\n",
    "    idx = clus\n",
    "    train = train_loaders[idx]\n",
    "    test = test_loaders[idx]\n",
    "#     mini = min_cards[idx]\n",
    "#     maxi = max_cards[idx]\n",
    "    prev_best_error = 100000.0\n",
    "    cnn_parameters, cnn_models = [], []\n",
    "    episode = 5\n",
    "    queries_dimension = 128\n",
    "    threshold_model = Threshold_Model()\n",
    "    error, next_cnn_parameters, next_cnn_models,next_output_model = select_best_layer(prev_best_error, cnn_parameters, cnn_models, threshold_model, train, test, episode, queries_dimension)\n",
    "    saved_error, saved_next_cnn_parameters, saved_next_cnn_models,saved_next_output_model = error, next_cnn_parameters, next_cnn_models,next_output_model\n",
    "    while error is not None:\n",
    "        saved_error, saved_next_cnn_parameters, saved_next_cnn_models,saved_next_output_model = error, next_cnn_parameters, next_cnn_models,next_output_model\n",
    "        print ('Cluster: {}, Error: {}, CNN Layer Num: {}, Added CNN Layer: {}'.format(clus, error, len(next_cnn_parameters), next_cnn_parameters[-1]))\n",
    "        error, next_cnn_parameters, next_cnn_models,next_output_model = select_best_layer(error, next_cnn_parameters, next_cnn_models, threshold_model, train, test, episode, queries_dimension)\n",
    "    errors[clus] = saved_error\n",
    "    next_cnn_parameterss[clus] = saved_next_cnn_parameters\n",
    "    next_cnn_modelss[clus] = saved_next_cnn_models\n",
    "    next_output_models[clus] = saved_next_output_model\n",
    "    threshold_models[clus] = threshold_model\n",
    "\n",
    "def construct_model():\n",
    "    errors = []\n",
    "    next_cnn_parameterss = []\n",
    "    next_cnn_modelss = []\n",
    "    next_output_models = []\n",
    "    threshold_models = []\n",
    "    for clus in range(100):\n",
    "        print ('Begin Cluster: {}'.format(clus))\n",
    "        idx = clus\n",
    "        train = train_loaders[idx]\n",
    "        test = test_loaders[idx]\n",
    "#         mini = min_cards[idx]\n",
    "#         maxi = max_cards[idx]\n",
    "        prev_best_error = 100000.0\n",
    "        cnn_parameters, cnn_models = [], []\n",
    "        episode = 5\n",
    "        queries_dimension = 128\n",
    "        threshold_model = Threshold_Model()\n",
    "        error, next_cnn_parameters, next_cnn_models,next_output_model = select_best_layer(prev_best_error, cnn_parameters, cnn_models, threshold_model, train, test, episode, queries_dimension)\n",
    "        saved_error, saved_next_cnn_parameters, saved_next_cnn_models,saved_next_output_model = error, next_cnn_parameters, next_cnn_models,next_output_model\n",
    "        while error is not None:\n",
    "            saved_error, saved_next_cnn_parameters, saved_next_cnn_models,saved_next_output_model = error, next_cnn_parameters, next_cnn_models,next_output_model\n",
    "            print ('Cluster: {}, Error: {}, CNN Layer Num: {}, Added CNN Layer: {}'.format(clus, error, len(next_cnn_parameters), next_cnn_parameters[-1]))\n",
    "            error, next_cnn_parameters, next_cnn_models,next_output_model = select_best_layer(error, next_cnn_parameters, next_cnn_models, threshold_model, train, test, episode, queries_dimension)\n",
    "        errors.append(saved_error)\n",
    "        next_cnn_parameterss.append(saved_next_cnn_parameters)\n",
    "        next_cnn_modelss.append(saved_next_cnn_models)\n",
    "        next_output_models.append(saved_next_output_model)\n",
    "        threshold_models.append(threshold_model)\n",
    "    return errors, next_cnn_parameterss, next_cnn_modelss, next_output_models, threshold_models\n",
    "\n",
    "class TunableParameters():\n",
    "    \n",
    "    def __init__(self, out_channel, kernel_size, stride, padding, pool_size, pool_type):\n",
    "        self.out_channel = out_channel\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.pool_size = pool_size\n",
    "        self.pool_type = pool_type\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self.out_channel) +' '+ str(self.kernel_size) +' '+ str(self.stride) +' '+ str(self.padding) +' '+ str(self.pool_size) +' '+ str(self.pool_type)\n",
    " \n",
    "    def __str__(self):\n",
    "        return str(self.out_channel) +' '+ str(self.kernel_size) +' '+ str(self.stride) +' '+ str(self.padding) +' '+ str(self.pool_size) +' '+ str(self.pool_type)\n",
    "\n",
    "def select_best_layer(prev_best_error, cnn_parameters, cnn_models, threshold_model, train, test, episode, queries_dimension):\n",
    "    print ('Input Model Size: {}'.format(len(cnn_parameters)))\n",
    "    if len(cnn_parameters) > 0:\n",
    "        in_channel = cnn_parameters[-1].out_channel\n",
    "    else:\n",
    "        in_channel = 1\n",
    "    in_size = queries_dimension\n",
    "    for para in cnn_parameters:\n",
    "        in_size = int((int((in_size - para.kernel_size + 2*(para.padding)) / para.stride) + 1) / para.pool_size)\n",
    "        print(para.kernel_size, para.padding, para.stride, para.pool_size, in_size)\n",
    "    \n",
    "    if in_size < 10 or len(cnn_parameters) > 5:\n",
    "        return None, None, None, None\n",
    "    \n",
    "    current_paras = []\n",
    "    current_paras.append(TunableParameters(8,2,1,0,2,0))\n",
    "#     current_paras.append(TunableParameters(8,10,1,3,10,0))\n",
    "#     current_paras.append(TunableParameters(4,5,3,2,5,0))\n",
    "#     current_paras.append(TunableParameters(4,3,1,0,3,0))\n",
    "    current_paras.append(TunableParameters(2,2,1,0,2,0))\n",
    "    \n",
    "#     for out_channel in [2,4,8]:\n",
    "#         for kernel_size in [2,4,8]:\n",
    "#             for stride in range(1, min(4, kernel_size)):\n",
    "#                 for padding in [0,2]:\n",
    "#                     for pool_size in [kernel_size,]:\n",
    "#                         for pool_type in [0,]:\n",
    "#                             current_paras.append(TunableParameters(out_channel,kernel_size,stride,padding,pool_size,pool_type))\n",
    "    print ('Group of parameters: {}'.format(len(current_paras)))\n",
    "    next_cnn_models = []\n",
    "    next_cnn_parameters = []\n",
    "    next_output_model = None\n",
    "#     current_paras = sample(current_paras, 2)\n",
    "    for para in current_paras:\n",
    "        print (para)\n",
    "        in_size_local = int((int((in_size - para.kernel_size + 2*(para.padding)) / para.stride) + 1) / para.pool_size)\n",
    "        if in_size_local < 10:\n",
    "            continue\n",
    "        print (in_size_local, para.out_channel)\n",
    "        output_model = Output_Model(in_size_local * para.out_channel)\n",
    "        added_cnn_layer = CNN_Model(in_channel, para.out_channel, para.kernel_size, para.stride, para.padding, para.pool_type, para.pool_size)\n",
    "        paras = [{\"params\": model.parameters()} for model in cnn_models]\n",
    "        paras.append({\"params\": added_cnn_layer.parameters()})\n",
    "        paras.append({\"params\": threshold_model.parameters()})\n",
    "        paras.append({\"params\": output_model.parameters()})\n",
    "        opt = optim.Adam(paras, lr=0.001)\n",
    "        new_cnn_models = []\n",
    "        for model in cnn_models:\n",
    "            new_cnn_models.append(model)\n",
    "        new_cnn_models.append(added_cnn_layer)\n",
    "        error = train_and_test(new_cnn_models, threshold_model, output_model, opt, train, test, episode)\n",
    "        if error < prev_best_error - 0.1:\n",
    "            prev_best_error = error\n",
    "            new_cnn_parameters = []\n",
    "            for para_old in cnn_parameters:\n",
    "                new_cnn_parameters.append(para_old)\n",
    "            next_output_model = output_model\n",
    "            new_cnn_parameters.append(para)\n",
    "            print ('Update layer: {}'.format(len(new_cnn_parameters)))\n",
    "            next_cnn_parameters = new_cnn_parameters\n",
    "            next_cnn_models = new_cnn_models\n",
    "    if len(next_cnn_models) == 0:\n",
    "        return None, None, None, None\n",
    "    return prev_best_error, next_cnn_parameters, next_cnn_models, next_output_model\n",
    "        \n",
    "\n",
    "def only_test(cnn_models, threshold_model, output_model, test):\n",
    "#     embed_model.eval()\n",
    "    for model in cnn_models:\n",
    "        model.eval()\n",
    "    threshold_model.eval()\n",
    "    output_model.eval()\n",
    "    q_errors = []\n",
    "    start = time.time()\n",
    "    for batch_idx, (masks, queries, thresholds, targets) in enumerate(test):\n",
    "        queries = torch.FloatTensor(data_test[queries.type(torch.LongTensor)].astype(float) / normalize_factor)\n",
    "        queries = Variable(queries)\n",
    "        thresholds = Variable(thresholds)\n",
    "        targets = Variable(targets)\n",
    "\n",
    "#         queries = embed_model(queries, masks)\n",
    "        batch_size = queries.shape[0]\n",
    "        join_size = queries.shape[1]\n",
    "        queries = queries.view(batch_size * join_size, -1)\n",
    "        queries = queries.unsqueeze(2).permute(0,2,1)\n",
    "    \n",
    "        for model in cnn_models:\n",
    "            queries = model(queries)\n",
    "        queries = (queries.view(batch_size, join_size, -1) * masks).sum(dim=1) / 100.0\n",
    "#         queries = queries.view(queries.shape[0], -1)\n",
    "    \n",
    "        threshold = threshold_model(thresholds)\n",
    "        estimates = output_model(queries, threshold)\n",
    "\n",
    "#         loss = l1_loss(estimates, targets)\n",
    "        \n",
    "        esti = torch.exp(estimates)\n",
    "        for i in range(esti.shape[0]):\n",
    "            if esti[i] > targets[i] + 0.1:\n",
    "                q_errors.append((esti[i] / (targets[i] + 0.1)).item())\n",
    "            else:\n",
    "                q_errors.append(((targets[i] + 0.1) / esti[i]).item())\n",
    "    end = time.time()\n",
    "    mean = np.mean(q_errors)\n",
    "    percent90 = np.percentile(q_errors, 90)\n",
    "    percent95 = np.percentile(q_errors, 95)\n",
    "    percent99 = np.percentile(q_errors, 99)\n",
    "    median = np.median(q_errors)\n",
    "    maxi = np.max(q_errors)\n",
    "    print ('Testing: Mean Error {}, Median Error {}, 90 Percent {}, 95 Percent {}, 99 Percent {}, Max Percent {}, Latency {}'\n",
    "           .format(mean, median, percent90, percent95, percent99, maxi, (end - start) / len(q_errors)))\n",
    "    return (end - start) / len(q_errors) / 100\n",
    "    \n",
    "\n",
    "def train_and_test(cnn_models, threshold_model, output_model, opt, train, test, episode):\n",
    "    print ('size: {}'.format(len(train)))\n",
    "    test_errors = []\n",
    "    for e in range(episode):\n",
    "#         embed_model.train()\n",
    "        for model in cnn_models:\n",
    "            model.train()\n",
    "        threshold_model.train()\n",
    "        output_model.train()\n",
    "        for batch_idx, (masks, queries, thresholds, targets) in enumerate(train):\n",
    "#             print (e, batch_idx)\n",
    "#             print (queries.shape)\n",
    "    #         print (torch.cat((queries, thresholds), 1)[0])\n",
    "            queries = torch.FloatTensor(data_test[queries.type(torch.LongTensor)].astype(float) / normalize_factor)\n",
    "            queries = Variable(queries)\n",
    "            thresholds = Variable(thresholds)\n",
    "            targets = Variable(targets)\n",
    "    #         print (targets)\n",
    "            opt.zero_grad()\n",
    "#             queries = embed_model(queries, masks)\n",
    "#             print (queries.shape)\n",
    "            batch_size = queries.shape[0]\n",
    "            join_size = queries.shape[1]\n",
    "            queries = queries.view(batch_size * join_size, -1)\n",
    "            queries = queries.unsqueeze(2).permute(0,2,1)\n",
    "#             print (queries.shape)\n",
    "            for model in cnn_models:\n",
    "                queries = model(queries)\n",
    "#             print (masks.shape)\n",
    "            queries = (queries.view(batch_size, join_size, -1) * masks).sum(dim=1) / 100.0\n",
    "#             queries = queries.view(queries.shape[0], -1)\n",
    "#             print (queries.shape)\n",
    "                \n",
    "            \n",
    "            threshold = threshold_model(thresholds)\n",
    "            estimates = output_model(queries, threshold)\n",
    "            \n",
    "            loss = l1_loss(estimates, targets)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "#             for p in model.parameters():\n",
    "#                 p.data.clamp_(-10, 10)\n",
    "            next(threshold_model.fc1.parameters()).data.clamp_(0)\n",
    "            next(threshold_model.fc2.parameters()).data.clamp_(0)\n",
    "#             next(output_model.fc1.parameters()).data.clamp_(0)\n",
    "            next(output_model.fc2.parameters()).data.clamp_(0)\n",
    "#             if batch_idx % 100 == 0:\n",
    "#                 print('Training: Iteration {0}, Batch {1}, Loss {2}'.format(e, batch_idx, loss.item()))\n",
    "#                 print(cnn_models[0].layer[0].weight.grad)\n",
    "        \n",
    "#         embed_model.eval()\n",
    "        for model in cnn_models:\n",
    "            model.eval()\n",
    "        threshold_model.eval()\n",
    "        output_model.eval()\n",
    "        test_loss = 0.0\n",
    "        mse_error = 0.0\n",
    "        q_mean = 0.0\n",
    "        q_max = 0.0\n",
    "        for batch_idx, (masks, queries, thresholds, targets) in enumerate(test):\n",
    "            queries = torch.FloatTensor(data_test[queries.type(torch.LongTensor)].astype(float) / normalize_factor)\n",
    "            queries = Variable(queries)\n",
    "            thresholds = Variable(thresholds)\n",
    "            targets = Variable(targets)\n",
    "#             queries = embed_model(queries, masks)\n",
    "            \n",
    "            batch_size = queries.shape[0]\n",
    "            join_size = queries.shape[1]\n",
    "            queries = queries.view(batch_size * join_size, -1)\n",
    "            queries = queries.unsqueeze(2).permute(0,2,1)\n",
    "            for model in cnn_models:\n",
    "                queries = model(queries)\n",
    "            queries = (queries.view(batch_size, join_size, -1) * masks).sum(dim=1) / 100.0\n",
    "#             queries = queries.view(queries.shape[0], -1)\n",
    "            \n",
    "            threshold = threshold_model(thresholds)\n",
    "            estimates = output_model(queries, threshold)\n",
    "            \n",
    "            loss = l1_loss(estimates, targets)\n",
    "            mse, qer_mean, qer_max = print_loss(estimates, targets)\n",
    "            test_loss += loss.item()\n",
    "            mse_error += mse.item()\n",
    "            q_mean += qer_mean\n",
    "            if qer_max > q_max:\n",
    "                q_max = qer_max\n",
    "        test_loss /= len(test)\n",
    "        mse_error /= len(test)\n",
    "        q_mean /= len(test)\n",
    "        test_errors.append(q_mean)\n",
    "        print ('Testing: Iteration {0}, Loss {1}, MSE_error {2}, Q_error_mean {3}, Q_error_max {4}'.format(e, test_loss, mse_error, q_mean, q_max))\n",
    "    return np.mean(test_errors[-3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Model Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Cluster: 0\n",
      "Input Model Size: 0\n",
      "Group of parameters: 2\n",
      "8 2 1 0 2 0\n",
      "63 8\n",
      "size: 205\n",
      "Testing: Iteration 0, Loss 81.51067209243774, MSE_error 2861113606.4, Q_error_mean 81.51067562315147, Q_error_max 1155.2874755859375\n",
      "Testing: Iteration 1, Loss 79.18724088668823, MSE_error 2855845209.6, Q_error_mean 79.18724065094092, Q_error_max 1083.8870849609375\n",
      "Testing: Iteration 2, Loss 69.85076398849488, MSE_error 2862873504.0, Q_error_mean 69.85076462066334, Q_error_max 784.1994018554688\n",
      "Testing: Iteration 3, Loss 62.12187910079956, MSE_error 2849778355.2, Q_error_mean 62.12187842729147, Q_error_max 722.6392211914062\n",
      "Testing: Iteration 4, Loss 53.36236152648926, MSE_error 2834699872.0, Q_error_mean 53.36235909099905, Q_error_max 836.7525634765625\n",
      "Update layer: 1\n",
      "2 2 1 0 2 0\n",
      "63 2\n",
      "size: 205\n",
      "Testing: Iteration 0, Loss 57.83335962295532, MSE_error 2839452057.6, Q_error_mean 57.83336022499181, Q_error_max 760.0655517578125\n",
      "Testing: Iteration 1, Loss 54.02336883544922, MSE_error 2840692592.0, Q_error_mean 54.02336780237484, Q_error_max 692.8846435546875\n",
      "Testing: Iteration 2, Loss 50.63164644241333, MSE_error 2832899936.0, Q_error_mean 50.63164946465598, Q_error_max 799.3697509765625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-00eb08781420>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_cnn_parameterss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_cnn_modelss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_output_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-e22566b1c2d0>\u001b[0m in \u001b[0;36mconstruct_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mqueries_dimension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mthreshold_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mThreshold_Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_cnn_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_cnn_models\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnext_output_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_best_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_best_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueries_dimension\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0msaved_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaved_next_cnn_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaved_next_cnn_models\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msaved_next_output_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_cnn_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_cnn_models\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnext_output_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-e22566b1c2d0>\u001b[0m in \u001b[0;36mselect_best_layer\u001b[0;34m(prev_best_error, cnn_parameters, cnn_models, threshold_model, train, test, episode, queries_dimension)\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0mnew_cnn_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mnew_cnn_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madded_cnn_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_cnn_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mprev_best_error\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mprev_best_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-e22566b1c2d0>\u001b[0m in \u001b[0;36mtrain_and_test\u001b[0;34m(cnn_models, threshold_model, output_model, opt, train, test, episode)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;31m#             print (queries.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcnn_models\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                 \u001b[0mqueries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;31m#             print (masks.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0mqueries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m100.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-3ac460136982>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mhid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;31m#         print (hid.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m#         hid = F.relu(self.n3(hid))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1621\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   1622\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1623\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1624\u001b[0m     )\n\u001b[1;32m   1625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "errors, next_cnn_parameterss, next_cnn_modelss, next_output_models, threshold_models = construct_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Cluster: 60\n",
      "Input Model Size: 0\n",
      "Group of parameters: 2\n",
      "8 2 1 0 2 0\n",
      "63 8\n",
      "size: 274\n",
      "Testing: Iteration 0, Loss 94.26186077411359, MSE_error 19612013686.153847, Q_error_mean 94.26186032007591, Q_error_max 3215.726318359375\n",
      "Testing: Iteration 1, Loss 87.66302761664757, MSE_error 19161776285.53846, Q_error_mean 87.6630324665457, Q_error_max 2545.479736328125\n",
      "Testing: Iteration 2, Loss 77.21873774895302, MSE_error 18787330225.23077, Q_error_mean 77.21873489964324, Q_error_max 2042.457763671875\n",
      "Testing: Iteration 3, Loss 65.88979244232178, MSE_error 18590377107.692307, Q_error_mean 65.88979472723216, Q_error_max 1721.9356689453125\n",
      "Testing: Iteration 4, Loss 51.0969800215501, MSE_error 18719203367.384617, Q_error_mean 51.09698021512192, Q_error_max 2168.81298828125\n",
      "Update layer: 1\n",
      "2 2 1 0 2 0\n",
      "63 2\n",
      "size: 274\n",
      "Testing: Iteration 0, Loss 58.281408896813026, MSE_error 18503558587.076923, Q_error_mean 58.2814112856017, Q_error_max 1670.284423828125\n",
      "Testing: Iteration 1, Loss 54.69084409567026, MSE_error 18682236652.307693, Q_error_mean 54.69084498941755, Q_error_max 1641.4881591796875\n",
      "Testing: Iteration 2, Loss 54.20747419504019, MSE_error 19012192000.0, Q_error_mean 54.20747527234758, Q_error_max 1987.7811279296875\n",
      "Testing: Iteration 3, Loss 49.35614226414607, MSE_error 18456834146.46154, Q_error_mean 49.35614249405738, Q_error_max 2559.44482421875\n",
      "Testing: Iteration 4, Loss 47.640184072347786, MSE_error 18480625821.53846, Q_error_mean 47.64018355281307, Q_error_max 2846.012939453125\n",
      "Update layer: 1\n",
      "Cluster: 60, Error: 50.40126710640601, CNN Layer Num: 1, Added CNN Layer: 2 2 1 0 2 0\n",
      "Input Model Size: 1\n",
      "2 0 1 2 63\n",
      "Group of parameters: 2\n",
      "8 2 1 0 2 0\n",
      "31 8\n",
      "size: 274\n",
      "Testing: Iteration 0, Loss 40.7758412361145, MSE_error 18201274348.307693, Q_error_mean 40.77583881517729, Q_error_max 4694.9990234375\n",
      "Testing: Iteration 1, Loss 35.09456553825965, MSE_error 18161613764.923077, Q_error_mean 35.09456621491923, Q_error_max 4969.232421875\n",
      "Testing: Iteration 2, Loss 29.342020988464355, MSE_error 17512873550.76923, Q_error_mean 29.34202140621626, Q_error_max 6317.92041015625\n",
      "Testing: Iteration 3, Loss 24.40846696266761, MSE_error 16794317233.23077, Q_error_mean 24.408466091343705, Q_error_max 7842.90283203125\n",
      "Testing: Iteration 4, Loss 23.44123440522414, MSE_error 13927946289.23077, Q_error_mean 23.441234690173026, Q_error_max 14214.5078125\n",
      "Update layer: 2\n",
      "2 2 1 0 2 0\n",
      "31 2\n",
      "size: 274\n",
      "Testing: Iteration 0, Loss 34.864189037909874, MSE_error 18048282446.76923, Q_error_mean 34.86418924957084, Q_error_max 9681.6630859375\n",
      "Testing: Iteration 1, Loss 33.75801099263705, MSE_error 17968889836.307693, Q_error_mean 33.75801124703139, Q_error_max 9928.9677734375\n",
      "Testing: Iteration 2, Loss 31.358578113409187, MSE_error 17573961885.53846, Q_error_mean 31.358578340472796, Q_error_max 8436.2060546875\n",
      "Testing: Iteration 3, Loss 29.665240086041965, MSE_error 17199759143.384617, Q_error_mean 29.66524131893395, Q_error_max 7583.30517578125\n",
      "Testing: Iteration 4, Loss 27.922936769632194, MSE_error 17603680945.23077, Q_error_mean 27.922936563971096, Q_error_max 6746.38427734375\n",
      "Cluster: 60, Error: 25.730574062577663, CNN Layer Num: 2, Added CNN Layer: 8 2 1 0 2 0\n",
      "Input Model Size: 2\n",
      "2 0 1 2 63\n",
      "2 0 1 2 31\n",
      "Group of parameters: 2\n",
      "8 2 1 0 2 0\n",
      "15 8\n",
      "size: 274\n",
      "Testing: Iteration 0, Loss 27.652215755902805, MSE_error 17012710734.76923, Q_error_mean 27.65221539564216, Q_error_max 4638.04443359375\n",
      "Testing: Iteration 1, Loss 27.591122737297646, MSE_error 16969787217.846153, Q_error_mean 27.5911221533763, Q_error_max 5253.39306640625\n",
      "Testing: Iteration 2, Loss 27.373535009530876, MSE_error 17173111650.461538, Q_error_mean 27.373535939922128, Q_error_max 6041.50537109375\n",
      "Testing: Iteration 3, Loss 27.004601680315456, MSE_error 17207258052.923077, Q_error_mean 27.004601950434825, Q_error_max 6298.2666015625\n",
      "Testing: Iteration 4, Loss 26.17608411495502, MSE_error 16767983143.384615, Q_error_mean 26.17608468632142, Q_error_max 6894.8271484375\n",
      "2 2 1 0 2 0\n",
      "15 2\n",
      "size: 274\n",
      "Testing: Iteration 0, Loss 31.970434995797966, MSE_error 17436672118.153847, Q_error_mean 31.97043475605404, Q_error_max 15582.9345703125\n",
      "Testing: Iteration 1, Loss 30.008105754852295, MSE_error 17447180563.692307, Q_error_mean 30.008107313940016, Q_error_max 14254.10546875\n",
      "Testing: Iteration 2, Loss 26.868099689483643, MSE_error 16975156903.384615, Q_error_mean 26.868099618237466, Q_error_max 11454.25\n",
      "Testing: Iteration 3, Loss 24.639856778658352, MSE_error 16360522545.23077, Q_error_mean 24.639856214402243, Q_error_max 9794.1533203125\n",
      "Testing: Iteration 4, Loss 23.210652167980488, MSE_error 15902483377.23077, Q_error_mean 23.21065193746024, Q_error_max 9153.25\n",
      "Update layer: 3\n",
      "Cluster: 60, Error: 24.906202590033317, CNN Layer Num: 3, Added CNN Layer: 2 2 1 0 2 0\n",
      "Input Model Size: 3\n",
      "2 0 1 2 63\n",
      "2 0 1 2 31\n",
      "2 0 1 2 15\n",
      "Group of parameters: 2\n",
      "8 2 1 0 2 0\n",
      "2 2 1 0 2 0\n"
     ]
    }
   ],
   "source": [
    "repair_specific_local_model(errors, next_cnn_parameterss, next_cnn_modelss, next_output_models, threshold_models, 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sunji/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:21: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: Mean Error 447.81279568021466, Median Error 211.2052993774414, 90 Percent 1301.79248046875, 95 Percent 1395.4632812500001, 99 Percent 1489.0597143554687, Max Percent 1563.456787109375, Latency 0.0019661059393685245\n",
      "1\n",
      "Testing: Mean Error 1898.3724183578497, Median Error 1035.268798828125, 90 Percent 5165.501464843751, 95 Percent 5548.729931640625, 99 Percent 6016.886259765628, Max Percent 6393.23193359375, Latency 0.0017432453011857157\n",
      "2\n",
      "Testing: Mean Error 983.9532900311067, Median Error 661.975830078125, 90 Percent 2391.675634765625, 95 Percent 2557.7495605468744, 99 Percent 2894.027392578124, Max Percent 3316.510498046875, Latency 0.0022145631488608942\n",
      "3\n",
      "Testing: Mean Error 508.2529366381314, Median Error 297.52105712890625, 90 Percent 1313.9614990234377, 95 Percent 1433.7537353515625, 99 Percent 1545.8207177734375, Max Percent 1600.2108154296875, Latency 0.0019091818376694987\n",
      "4\n",
      "Testing: Mean Error 863.2523985926506, Median Error 571.4645385742188, 90 Percent 2120.9865234375, 95 Percent 2257.8272705078125, 99 Percent 2469.967744140625, Max Percent 2751.38134765625, Latency 0.001801258251990801\n",
      "5\n",
      "Testing: Mean Error 583.7623900142187, Median Error 445.2771911621094, 90 Percent 1327.0525146484376, 95 Percent 1396.6307373046875, 99 Percent 1519.9590917968749, Max Percent 1598.7816162109375, Latency 0.0016895732524232095\n",
      "6\n",
      "Testing: Mean Error 140.62305159375848, Median Error 35.793779373168945, 90 Percent 474.72925720214806, 95 Percent 634.009649658203, 99 Percent 817.9424328613283, Max Percent 896.3715209960938, Latency 0.002386839059046927\n",
      "7\n",
      "Testing: Mean Error 722.8404831445791, Median Error 346.68743896484375, 90 Percent 2024.021728515625, 95 Percent 2276.8309326171875, 99 Percent 2654.5985839843743, Max Percent 3045.94482421875, Latency 0.0019139338533797768\n",
      "8\n",
      "Testing: Mean Error 491.3522109320391, Median Error 259.8966369628906, 90 Percent 1337.89453125, 95 Percent 1449.6193603515624, 99 Percent 1637.6275878906251, Max Percent 1771.84228515625, Latency 0.001664365764563756\n",
      "9\n",
      "Testing: Mean Error 199.744115252328, Median Error 185.7222900390625, 90 Percent 352.96748657226567, 95 Percent 406.3694183349609, 99 Percent 494.52149963378906, Max Percent 532.6859130859375, Latency 0.0019196710503136104\n",
      "10\n",
      "Testing: Mean Error 183.39387713824385, Median Error 144.0749740600586, 90 Percent 415.0113983154297, 95 Percent 443.61382751464845, 99 Percent 483.7356549072268, Max Percent 510.39288330078125, Latency 0.003304367531460338\n",
      "11\n",
      "Testing: Mean Error 741.8150045553663, Median Error 370.6719970703125, 90 Percent 2068.670849609375, 95 Percent 2255.660229492186, 99 Percent 2500.958920898437, Max Percent 2766.553466796875, Latency 0.0018516251830016674\n",
      "12\n",
      "Testing: Mean Error 380.786730823247, Median Error 302.7742614746094, 90 Percent 851.5719177246094, 95 Percent 899.3867279052733, 99 Percent 959.0248120117187, Max Percent 998.297119140625, Latency 0.0032979103983664998\n",
      "13\n",
      "Testing: Mean Error 278.3738497077191, Median Error 192.21988677978516, 90 Percent 678.1516723632814, 95 Percent 718.8159149169923, 99 Percent 792.6588867187502, Max Percent 823.4732666015625, Latency 0.001813573051368\n",
      "14\n",
      "Testing: Mean Error 350.2333094550767, Median Error 227.7323760986328, 90 Percent 882.5941772460938, 95 Percent 937.5035095214844, 99 Percent 1007.9259826660157, Max Percent 1084.751220703125, Latency 0.0018325967579523206\n",
      "15\n",
      "Testing: Mean Error 369.5368948736645, Median Error 333.3415985107422, 90 Percent 751.6617492675781, 95 Percent 804.4312225341796, 99 Percent 861.8798284912109, Max Percent 900.5086669921875, Latency 0.0018014937355404809\n",
      "16\n",
      "Testing: Mean Error 575.1424167772003, Median Error 317.18548583984375, 90 Percent 1568.6324462890625, 95 Percent 1683.8480224609375, 99 Percent 1792.9785644531257, Max Percent 1996.425537109375, Latency 0.0018603142882455622\n",
      "17\n",
      "Testing: Mean Error 393.40029199378915, Median Error 225.4234619140625, 90 Percent 1003.9857177734375, 95 Percent 1082.7958740234371, 99 Percent 1209.698837890625, Max Percent 1272.720458984375, Latency 0.0019152288708832177\n",
      "18\n",
      "Testing: Mean Error 1520.6981231594643, Median Error 1029.9921875, 90 Percent 3690.7459472656255, 95 Percent 3963.1683593750004, 99 Percent 4406.636640625, Max Percent 4570.72705078125, Latency 0.0018676195726259211\n",
      "19\n",
      "Testing: Mean Error 334.8571367466563, Median Error 193.82999420166016, 90 Percent 884.6234741210939, 95 Percent 938.4066772460935, 99 Percent 1000.0925689697261, Max Percent 1049.831298828125, Latency 0.0019161291892015482\n",
      "20\n",
      "Testing: Mean Error 169.0787712584634, Median Error 131.65687561035156, 90 Percent 383.0889038085938, 95 Percent 402.0797180175781, 99 Percent 418.76430725097646, Max Percent 429.5717468261719, Latency 0.0017277973515170437\n",
      "21\n",
      "Testing: Mean Error 1371.1013118415924, Median Error 662.742919921875, 90 Percent 3821.77060546875, 95 Percent 4232.57041015625, 99 Percent 4978.77845703125, Max Percent 5462.0400390625, Latency 0.001709704335261769\n",
      "22\n",
      "Testing: Mean Error 617.7584168150772, Median Error 353.0008087158203, 90 Percent 1612.2873657226562, 95 Percent 1743.1287841796873, 99 Percent 1947.9720166015627, Max Percent 2320.315185546875, Latency 0.0019358826113176776\n",
      "23\n",
      "Testing: Mean Error 707.0696412137723, Median Error 519.6206665039062, 90 Percent 1632.492065429688, 95 Percent 1758.4225341796873, 99 Percent 2005.5844299316404, Max Percent 2239.1826171875, Latency 0.003394083876915166\n",
      "24\n",
      "Testing: Mean Error 318.21243318282626, Median Error 243.75457763671875, 90 Percent 714.3655029296875, 95 Percent 767.2296203613281, 99 Percent 848.2264868164059, Max Percent 876.0822143554688, Latency 0.0018904698393715585\n",
      "25\n",
      "Testing: Mean Error 959.0827354706042, Median Error 1307.7394409179688, 90 Percent 1546.3953369140625, 95 Percent 1564.6189392089843, 99 Percent 1621.2432104492189, Max Percent 1653.5885009765625, Latency 0.0017913422908728926\n",
      "26\n",
      "Testing: Mean Error 563.302937750807, Median Error 244.3578338623047, 90 Percent 1677.5249877929687, 95 Percent 1820.051019287109, 99 Percent 1970.9726586914062, Max Percent 2101.150146484375, Latency 0.001746443397711709\n",
      "27\n",
      "Testing: Mean Error 305.98067582054387, Median Error 194.48532104492188, 90 Percent 769.8069763183594, 95 Percent 824.8172576904296, 99 Percent 877.4441003417971, Max Percent 927.6946411132812, Latency 0.001831689168666971\n",
      "28\n",
      "Testing: Mean Error 402.0058492149703, Median Error 387.8371276855469, 90 Percent 772.415625, 95 Percent 812.2617218017579, 99 Percent 898.6696844482416, Max Percent 936.036376953125, Latency 0.0018810718847076277\n",
      "29\n",
      "Testing: Mean Error 154.14205814235382, Median Error 155.50577545166016, 90 Percent 288.4551483154297, 95 Percent 302.22244415283205, 99 Percent 328.22744445800777, Max Percent 333.5702819824219, Latency 0.001756817554962092\n",
      "30\n",
      "Testing: Mean Error 438.4192863607908, Median Error 218.711669921875, 90 Percent 1235.1292724609375, 95 Percent 1328.849548339844, 99 Percent 1454.9253869628913, Max Percent 1559.1693115234375, Latency 0.00241250551498688\n",
      "31\n",
      "Testing: Mean Error 459.37585693966963, Median Error 207.47402954101562, 90 Percent 1307.45078125, 95 Percent 1491.2558593749995, 99 Percent 1745.4739501953109, Max Percent 1917.941162109375, Latency 0.0018845470426172932\n",
      "32\n",
      "Testing: Mean Error 649.8211601333495, Median Error 600.353759765625, 90 Percent 1276.4368896484375, 95 Percent 1326.527587890625, 99 Percent 1423.7862915039059, Max Percent 1512.3497314453125, Latency 0.001835023142345817\n",
      "33\n",
      "Testing: Mean Error 329.79639102917554, Median Error 225.20118713378906, 90 Percent 803.6689453125, 95 Percent 849.8477172851562, 99 Percent 963.9234008789062, Max Percent 1033.3399658203125, Latency 0.003428411893226689\n",
      "34\n",
      "Testing: Mean Error 51.026789593566754, Median Error 39.7733154296875, 90 Percent 118.69625396728516, 95 Percent 128.0324249267578, 99 Percent 139.62600952148438, Max Percent 155.45533752441406, Latency 0.001892427589878734\n",
      "35\n",
      "Testing: Mean Error 191.26035661094792, Median Error 149.19548797607422, 90 Percent 423.0383270263672, 95 Percent 454.9481536865235, 99 Percent 528.4367431640625, Max Percent 586.195556640625, Latency 0.0017558224908598176\n",
      "36\n",
      "Testing: Mean Error 471.86372064572794, Median Error 381.2068786621094, 90 Percent 1040.1125244140626, 95 Percent 1095.5913818359375, 99 Percent 1169.7982763671869, Max Percent 1276.666015625, Latency 0.001763928966757692\n",
      "37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: Mean Error 344.1731261049436, Median Error 200.19882202148438, 90 Percent 898.9041564941408, 95 Percent 976.6612091064453, 99 Percent 1040.9754455566406, Max Percent 1131.0338134765625, Latency 0.0034770737506952315\n",
      "38\n",
      "Testing: Mean Error 375.72324058998663, Median Error 275.7469940185547, 90 Percent 863.6901062011718, 95 Percent 931.8169067382812, 99 Percent 994.0290258789062, Max Percent 1022.8245849609375, Latency 0.0017135615036730715\n",
      "39\n",
      "Testing: Mean Error 159.66279918521528, Median Error 104.32349395751953, 90 Percent 394.8424011230469, 95 Percent 418.7636413574219, 99 Percent 442.7286242675781, Max Percent 459.1213073730469, Latency 0.0018134547936870325\n",
      "40\n",
      "Testing: Mean Error 2455.1810014553093, Median Error 2094.481201171875, 90 Percent 4905.163671875001, 95 Percent 6394.890039062499, 99 Percent 11948.481992187504, Max Percent 14942.0263671875, Latency 0.0018679349292518219\n",
      "41\n",
      "Testing: Mean Error 199.00498987963348, Median Error 120.1798324584961, 90 Percent 499.5623779296875, 95 Percent 542.36962890625, 99 Percent 685.0903686523438, Max Percent 731.3631591796875, Latency 0.0032480535139244315\n",
      "42\n",
      "Testing: Mean Error 734.4851336773881, Median Error 400.7040710449219, 90 Percent 2026.8706054687498, 95 Percent 2153.2418945312497, 99 Percent 2292.826025390625, Max Percent 2377.788330078125, Latency 0.0017496009238691182\n",
      "43\n",
      "Testing: Mean Error 593.4018060702033, Median Error 474.9255676269531, 90 Percent 1321.91015625, 95 Percent 1373.1606201171876, 99 Percent 1425.9492724609377, Max Percent 1451.44482421875, Latency 0.0018902856770639108\n",
      "44\n",
      "Testing: Mean Error 212.7698392196747, Median Error 130.63807678222656, 90 Percent 541.2886474609376, 95 Percent 584.4475189208983, 99 Percent 652.9986688232422, Max Percent 713.2776489257812, Latency 0.0017219358108368427\n",
      "45\n",
      "Testing: Mean Error 326.8096227364384, Median Error 159.20925903320312, 90 Percent 936.4165649414062, 95 Percent 1000.7488098144531, 99 Percent 1072.7881225585938, Max Percent 1136.27685546875, Latency 0.0016974083559950588\n",
      "46\n",
      "Testing: Mean Error 510.3307052051358, Median Error 332.5089416503906, 90 Percent 1254.526220703125, 95 Percent 1371.995947265625, 99 Percent 1571.0856201171878, Max Percent 1712.935302734375, Latency 0.0016700958011079997\n",
      "47\n",
      "Testing: Mean Error 935.1477357969052, Median Error 680.6968994140625, 90 Percent 2176.2931640625, 95 Percent 2352.950439453125, 99 Percent 2540.3086669921877, Max Percent 2709.35791015625, Latency 0.0017735934839016054\n",
      "48\n",
      "Testing: Mean Error 421.31560067748126, Median Error 304.32533264160156, 90 Percent 972.1838073730471, 95 Percent 1060.54443359375, 99 Percent 1299.7624121093743, Max Percent 1439.3343505859375, Latency 0.0016641811754718517\n",
      "49\n",
      "Testing: Mean Error 326.56446751218743, Median Error 282.6153106689453, 90 Percent 659.8134460449219, 95 Percent 739.4541168212891, 99 Percent 910.2400360107417, Max Percent 981.2427368164062, Latency 0.0017870869241556485\n",
      "50\n",
      "Testing: Mean Error 225.93123463753616, Median Error 146.93350982666016, 90 Percent 570.6350280761719, 95 Percent 609.1258697509766, 99 Percent 685.8746398925773, Max Percent 770.2675170898438, Latency 0.001738004079564203\n",
      "51\n",
      "Testing: Mean Error 204.41900879309665, Median Error 131.35320281982422, 90 Percent 508.01783752441406, 95 Percent 541.6840667724609, 99 Percent 592.9294067382813, Max Percent 626.6177978515625, Latency 0.0018497592025149652\n",
      "52\n",
      "Testing: Mean Error 422.88174710536794, Median Error 329.92926025390625, 90 Percent 942.2267089843749, 95 Percent 1003.0174102783201, 99 Percent 1076.0508056640624, Max Percent 1099.9666748046875, Latency 0.0018573935542787825\n",
      "53\n",
      "Testing: Mean Error 2480.153286507699, Median Error 2030.5647583007812, 90 Percent 5397.530859375001, 95 Percent 5789.695971679686, 99 Percent 6131.103466796873, Max Percent 6563.18310546875, Latency 0.0023944623739339034\n",
      "54\n",
      "Testing: Mean Error 504.0557323209102, Median Error 314.5855407714844, 90 Percent 1280.4355468749998, 95 Percent 1368.2347412109375, 99 Percent 1499.2667382812501, Max Percent 1684.650634765625, Latency 0.0017506928882979609\n",
      "55\n",
      "Testing: Mean Error 439.8220839102313, Median Error 549.8463745117188, 90 Percent 798.4022033691407, 95 Percent 815.8267547607422, 99 Percent 840.5354187011719, Max Percent 853.40673828125, Latency 0.0018486643737217166\n",
      "56\n",
      "Testing: Mean Error 341.967575144595, Median Error 245.8371124267578, 90 Percent 799.6945068359375, 95 Percent 859.8457183837891, 99 Percent 982.0930279541017, Max Percent 1150.6478271484375, Latency 0.0016717437384785087\n",
      "57\n",
      "Testing: Mean Error 1065.5892796917744, Median Error 531.5226440429688, 90 Percent 2999.3123291015627, 95 Percent 3219.606958007813, 99 Percent 3453.384611816406, Max Percent 3592.55859375, Latency 0.0018171666224310002\n",
      "58\n",
      "Testing: Mean Error 348.46543389447675, Median Error 175.5111083984375, 90 Percent 962.1251831054688, 95 Percent 1059.3887939453125, 99 Percent 1223.5461669921865, Max Percent 1302.85400390625, Latency 0.0018746253716954537\n",
      "59\n",
      "Testing: Mean Error 592.8071781966886, Median Error 370.22894287109375, 90 Percent 1489.396826171875, 95 Percent 1590.0788330078126, 99 Percent 1834.5685400390623, Max Percent 2168.8974609375, Latency 0.001721101909683872\n",
      "60\n",
      "Testing: Mean Error 671.1183823860283, Median Error 518.0006713867188, 90 Percent 1510.9823486328125, 95 Percent 1639.3694335937498, 99 Percent 1847.7516796875, Max Percent 2020.5721435546875, Latency 0.001715187054065861\n",
      "61\n",
      "Testing: Mean Error 260.88479216322764, Median Error 151.65959930419922, 90 Percent 686.3551635742188, 95 Percent 728.8543395996094, 99 Percent 781.4586755371093, Max Percent 859.3216552734375, Latency 0.0017778569867151865\n",
      "62\n",
      "Testing: Mean Error 409.83984448844166, Median Error 359.1728820800781, 90 Percent 840.1850219726562, 95 Percent 884.6769897460936, 99 Percent 962.6512988281249, Max Percent 997.4417114257812, Latency 0.002402343737796874\n",
      "63\n",
      "Testing: Mean Error 467.04146638192424, Median Error 191.73603057861328, 90 Percent 1377.9374145507813, 95 Percent 1524.5967529296877, 99 Percent 1720.1196838378905, Max Percent 1931.0313720703125, Latency 0.0018449437191335293\n",
      "64\n",
      "Testing: Mean Error 228.28531549395495, Median Error 120.67021179199219, 90 Percent 626.8972778320312, 95 Percent 668.1409881591796, 99 Percent 717.0924829101563, Max Percent 741.5923461914062, Latency 0.001776053887287169\n",
      "65\n",
      "Testing: Mean Error 600.7098456318937, Median Error 296.0157775878906, 90 Percent 1699.1922607421884, 95 Percent 1811.6051513671873, 99 Percent 1936.2451513671872, Max Percent 2054.1220703125, Latency 0.0017528420487301058\n",
      "66\n",
      "Testing: Mean Error 192.4844633867459, Median Error 137.04866790771484, 90 Percent 451.59504394531257, 95 Percent 481.606462097168, 99 Percent 533.2821740722657, Max Percent 582.4617309570312, Latency 0.0017600489932169732\n",
      "67\n",
      "Testing: Mean Error 535.414397046208, Median Error 378.4705352783203, 90 Percent 1291.9694335937502, 95 Percent 1361.5759826660155, 99 Percent 1438.2702941894531, Max Percent 1512.863037109375, Latency 0.0017715404970577349\n",
      "72\n",
      "Testing: Mean Error 276.9656945628344, Median Error 175.70672607421875, 90 Percent 694.676220703125, 95 Percent 750.1429687499998, 99 Percent 814.5008911132805, Max Percent 852.6845092773438, Latency 0.0017824701648379848\n",
      "73\n",
      "Testing: Mean Error 458.9143058179618, Median Error 358.5379638671875, 90 Percent 1026.713623046875, 95 Percent 1102.0771484375, 99 Percent 1191.706787109375, Max Percent 1263.8753662109375, Latency 0.0017841682988443124\n",
      "74\n",
      "Testing: Mean Error 593.906444832417, Median Error 285.6229248046875, 90 Percent 1718.1751708984375, 95 Percent 1843.5005249023436, 99 Percent 1984.496003417969, Max Percent 2078.3828125, Latency 0.0017795069933107556\n",
      "75\n",
      "Testing: Mean Error 1207.1419036316988, Median Error 1585.6546630859375, 90 Percent 1886.5104492187502, 95 Percent 1921.4180297851562, 99 Percent 1972.2508666992187, Max Percent 2009.8692626953125, Latency 0.002690691104482983\n",
      "76\n",
      "Testing: Mean Error 495.5238138887386, Median Error 331.5172424316406, 90 Percent 1220.7912109375, 95 Percent 1321.616271972656, 99 Percent 1450.5499755859375, Max Percent 1580.0948486328125, Latency 0.0018723302880607083\n",
      "77\n",
      "Testing: Mean Error 1254.5790847553724, Median Error 1141.480224609375, 90 Percent 2632.2957519531255, 95 Percent 2855.0667968749995, 99 Percent 3256.944794921875, Max Percent 3901.830810546875, Latency 0.0033552277606466543\n",
      "78\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: Mean Error 217.56743723618752, Median Error 118.04674530029297, 90 Percent 590.1504211425781, 95 Percent 631.8069946289063, 99 Percent 672.5086877441406, Max Percent 690.7998046875, Latency 0.0018391287487664859\n",
      "79\n",
      "Testing: Mean Error 413.244315495875, Median Error 200.3783416748047, 90 Percent 1170.918444824219, 95 Percent 1283.431408691406, 99 Percent 1362.2418652343752, Max Percent 1426.8348388671875, Latency 0.0016485647613487292\n",
      "80\n",
      "Testing: Mean Error 333.4630581339572, Median Error 257.3817443847656, 90 Percent 746.9732177734376, 95 Percent 809.4724853515625, 99 Percent 912.3710253906252, Max Percent 1007.8619384765625, Latency 0.0018823280512729537\n",
      "81\n",
      "Testing: Mean Error 1122.8005227457477, Median Error 1549.0689697265625, 90 Percent 1863.056396484375, 95 Percent 1900.1016296386717, 99 Percent 2010.0874047851564, Max Percent 2019.5701904296875, Latency 0.0017261035569751536\n",
      "82\n",
      "Testing: Mean Error 164.10833847713167, Median Error 158.30914306640625, 90 Percent 315.521240234375, 95 Percent 351.0093322753906, 99 Percent 425.28732727050783, Max Percent 452.7056579589844, Latency 0.001766051220309874\n",
      "83\n",
      "Testing: Mean Error 486.7928167382351, Median Error 280.7528076171875, 90 Percent 1280.1288452148438, 95 Percent 1371.1278015136718, 99 Percent 1470.1420312499997, Max Percent 1572.872802734375, Latency 0.001876755938662248\n",
      "84\n",
      "Testing: Mean Error 255.11314012601008, Median Error 225.4454803466797, 90 Percent 513.8935913085937, 95 Percent 558.1474609374998, 99 Percent 589.4918920898438, Max Percent 604.9440307617188, Latency 0.001686225720305941\n",
      "85\n",
      "Testing: Mean Error 620.0740403447328, Median Error 303.3097686767578, 90 Percent 1739.4155517578124, 95 Percent 1887.902124023437, 99 Percent 2134.87748046875, Max Percent 2291.808349609375, Latency 0.0018811909357706706\n",
      "86\n",
      "Testing: Mean Error 481.0619751800586, Median Error 604.6550598144531, 90 Percent 725.3110656738281, 95 Percent 750.5127502441405, 99 Percent 1394.5473132324205, Max Percent 1572.1470947265625, Latency 0.0017045299502184792\n",
      "87\n",
      "Testing: Mean Error 628.488249758482, Median Error 339.4502716064453, 90 Percent 1727.0201049804691, 95 Percent 1853.9558227539062, 99 Percent 2004.3489538574217, Max Percent 2133.189453125, Latency 0.0017779919079371862\n",
      "88\n",
      "Testing: Mean Error 148.84168148325423, Median Error 94.80765914916992, 90 Percent 378.1226165771485, 95 Percent 400.6803009033203, 99 Percent 420.40857757568364, Max Percent 436.940185546875, Latency 0.0018355021773474951\n",
      "89\n",
      "Testing: Mean Error 131.08527178567553, Median Error 95.27854919433594, 90 Percent 299.5833740234375, 95 Percent 322.39378662109374, 99 Percent 367.7707543945312, Max Percent 422.1551818847656, Latency 0.001686538817390563\n",
      "90\n",
      "Testing: Mean Error 386.3718138450852, Median Error 448.5185852050781, 90 Percent 649.5627319335938, 95 Percent 678.1047851562499, 99 Percent 731.277114257812, Max Percent 771.7906494140625, Latency 0.0018640515090302468\n",
      "91\n",
      "Testing: Mean Error 586.1576922781368, Median Error 207.7692413330078, 90 Percent 1871.650659179688, 95 Percent 2050.162915039062, 99 Percent 2225.9637011718755, Max Percent 2435.59228515625, Latency 0.0016731270307955438\n",
      "92\n",
      "Testing: Mean Error 551.0150340652704, Median Error 363.87928771972656, 90 Percent 1362.7092407226562, 95 Percent 1441.855908203125, 99 Percent 1509.6582055664062, Max Percent 1561.75439453125, Latency 0.0019686077279774798\n",
      "93\n",
      "Testing: Mean Error 377.267326112899, Median Error 285.5628356933594, 90 Percent 867.3269836425782, 95 Percent 920.292398071289, 99 Percent 991.002471923828, Max Percent 1077.5272216796875, Latency 0.001889961835836343\n",
      "94\n",
      "Testing: Mean Error 870.963550995384, Median Error 557.5530395507812, 90 Percent 2192.432373046875, 95 Percent 2344.506591796875, 99 Percent 2491.5193847656255, Max Percent 2720.92822265625, Latency 0.0022610967062753813\n",
      "95\n",
      "Testing: Mean Error 840.0147288962431, Median Error 626.3875122070312, 90 Percent 1945.6778564453127, 95 Percent 2072.7537109375003, 99 Percent 2302.222294921875, Max Percent 2376.289306640625, Latency 0.0016773489950123763\n",
      "96\n",
      "Testing: Mean Error 433.42876177180835, Median Error 234.26791381835938, 90 Percent 1190.183642578125, 95 Percent 1262.3486572265624, 99 Percent 1334.2217578124998, Max Percent 1473.02490234375, Latency 0.0033366295654538554\n",
      "97\n",
      "Testing: Mean Error 606.8089084738417, Median Error 336.9464111328125, 90 Percent 1634.308923339844, 95 Percent 1757.9237182617185, 99 Percent 1978.7774084472646, Max Percent 2137.354736328125, Latency 0.0017887870722179172\n",
      "98\n",
      "Testing: Mean Error 313.0458959809891, Median Error 230.83404541015625, 90 Percent 736.0255432128907, 95 Percent 767.0473052978516, 99 Percent 804.4153460693362, Max Percent 858.7986450195312, Latency 0.0017286639024571674\n",
      "99\n",
      "Testing: Mean Error 235.47993528868489, Median Error 139.760498046875, 90 Percent 615.781689453125, 95 Percent 656.3150390625, 99 Percent 706.0337219238281, Max Percent 738.6121826171875, Latency 0.001906208347814095\n"
     ]
    }
   ],
   "source": [
    "# embed_models = [Set_CNN(queries_dimension) for _ in range(cluster_size)]\n",
    "import time\n",
    "latencies = []\n",
    "for idx in range(cluster_size):\n",
    "    print (idx)\n",
    "    test = test_loaders[idx]\n",
    "    train = train_loaders[idx]\n",
    "    paras = list()\n",
    "    for mo in next_cnn_modelss[idx]:\n",
    "        paras += list(mo.parameters())\n",
    "#     paras += list(embed_models[idx].parameters())\n",
    "    paras += list(threshold_models[idx].parameters())\n",
    "    paras += list(next_output_models[idx].parameters())\n",
    "#     paras = [{\"params\": model.parameters()} for model in next_cnn_modelss[idx]]\n",
    "#     paras.append({\"params\": embed_models[idx].parameters()})\n",
    "#     paras.append({\"params\": threshold_models[idx].parameters()})\n",
    "#     paras.append({\"params\": next_output_models[idx].parameters()})\n",
    "    opt = optim.Adam(paras, lr=0.001)\n",
    "    episode = 3\n",
    "#     train_and_test(next_cnn_modelss[idx], threshold_models[idx], next_output_models[idx], opt, train, test, episode)\n",
    "    start = time.clock()\n",
    "    latency = only_test(next_cnn_modelss[idx], threshold_models[idx], next_output_models[idx], test)\n",
    "    latencies.append(latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0019746886035192537"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(latencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx in range(cluster_size):\n",
    "    states = {}\n",
    "#     states['join_set_model_state_dict'] = embed_models[idx].state_dict()\n",
    "    for idd, cnn_model in enumerate(next_cnn_modelss[idx]):\n",
    "        states['cnn_model_state_dict_' + str(idd)] = cnn_model.state_dict()\n",
    "    states['threshold_model_state_dict'] = threshold_models[idx].state_dict()\n",
    "    states['output_model_state_dict'] = next_output_models[idx].state_dict()\n",
    "    torch.save(states, '/home/sunji/ANN/join/sift_128_euclidean/local_sift_128_euclidean_cluster_' + str(idx) + '.model')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/home/sunji/ANN/join/sift_128_euclidean/cnn_hyper_parameters.hyperpara', 'w') as handle:\n",
    "    for idx in range(cluster_size):\n",
    "        handle.write(';'.join(str(x) for x in next_cnn_parameterss[idx]))\n",
    "        handle.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "hyper_parameterss = []\n",
    "with open('/home/sunji/ANN/'+dataset_id+'/saved_models/cnn_hyper_parameters.hyperpara', 'r') as handle:\n",
    "    for paras in handle.readlines():\n",
    "        hyper_parameters = []\n",
    "        for para in paras.split(';'):\n",
    "            para = para.split(' ')\n",
    "            hyper_parameters.append(TunableParameters(int(para[0]), int(para[1]), int(para[2]),\n",
    "                                                      int(para[3]), int(para[4]), int(para[5])))\n",
    "        hyper_parameterss.append(hyper_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_modelss = []\n",
    "threshold_models = []\n",
    "output_models = []\n",
    "for idx in range(cluster_size):\n",
    "    states = torch.load('/home/sunji/ANN/'+dataset_id+'/saved_models/local_'+dataset_id+'_cluster_' + str(idx) + '.model')\n",
    "    hyper_para = hyper_parameterss[idx]\n",
    "    cnn_models = []\n",
    "    weights = [None for _ in range(len(hyper_para))]\n",
    "    for key, value in states.items():\n",
    "        if key != 'threshold_model_state_dict' and key != 'output_model_state_dict':\n",
    "#             print (key)\n",
    "            layer_id = int(key.split('_')[-1])\n",
    "#             print (layer_id)\n",
    "            weights[layer_id] = value\n",
    "    in_channel = 1\n",
    "    in_size = queries_dimension\n",
    "    for weight_idx, weight in enumerate(weights):\n",
    "        hyper = hyper_para[weight_idx]\n",
    "        cnn_model = CNN_Model(in_channel, hyper.out_channel, hyper.kernel_size,\n",
    "                              hyper.stride, hyper.padding, hyper.pool_type, hyper.pool_size)\n",
    "        in_size = int((int((in_size - hyper.kernel_size + 2*(hyper.padding)) / hyper.stride) + 1) / hyper.pool_size)\n",
    "        in_channel = hyper.out_channel\n",
    "        cnn_model.load_state_dict(weight)\n",
    "        cnn_model.eval()\n",
    "        cnn_models.append(cnn_model)\n",
    "    cnn_modelss.append(cnn_models)\n",
    "        \n",
    "    threshold_model_state_dict = states['threshold_model_state_dict']\n",
    "    threshold_model = Threshold_Model()\n",
    "    threshold_model.load_state_dict(threshold_model_state_dict)\n",
    "    threshold_model.eval()\n",
    "    threshold_models.append(threshold_model)\n",
    "    \n",
    "    output_model_state_dict = states['output_model_state_dict']\n",
    "    output_model = Output_Model(in_size * in_channel)\n",
    "    output_model.load_state_dict(output_model_state_dict)\n",
    "    output_model.eval()\n",
    "    output_models.append(output_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_cnn_parameterss = hyper_parameterss\n",
    "next_cnn_modelss = cnn_modelss\n",
    "next_output_models = output_models\n",
    "errors = [0.0 for _ in range(cluster_size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model.load_state_dict(torch.load('MDN_model'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing For Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_test_baseline(mlp_model, threshold_model, output_model, test):\n",
    "#     embed_model.eval()\n",
    "    mlp_model.eval()\n",
    "    threshold_model.eval()\n",
    "    output_model.eval()\n",
    "    q_errors = []\n",
    "    for batch_idx, (masks, queries, thresholds, targets) in enumerate(test):\n",
    "        queries = torch.FloatTensor(data_test[queries.type(torch.LongTensor)].astype(float) / normalize_factor)\n",
    "        queries = Variable(queries)\n",
    "        thresholds = Variable(thresholds)\n",
    "        targets = Variable(targets)\n",
    "#         queries = embed_model(queries, masks)\n",
    "        batch_size = queries.shape[0]\n",
    "        join_size = queries.shape[1]\n",
    "        queries = queries.view(batch_size * join_size, -1)\n",
    "        queries = mlp_model(queries)\n",
    "        queries = (queries.view(batch_size, join_size, -1) * masks).sum(dim=1) / 100.0\n",
    "    \n",
    "        threshold = threshold_model(thresholds)\n",
    "        estimates = output_model(queries, threshold)\n",
    "\n",
    "        loss = l1_loss(estimates, targets)\n",
    "        \n",
    "        esti = torch.exp(estimates)\n",
    "        for i in range(esti.shape[0]):\n",
    "            if esti[i] > targets[i] + 0.1:\n",
    "                q_errors.append((esti[i] / (targets[i] + 0.1)).item())\n",
    "            else:\n",
    "                q_errors.append(((targets[i] + 0.1) / esti[i]).item())\n",
    "    mean = np.mean(q_errors)\n",
    "    percent90 = np.percentile(q_errors, 90)\n",
    "    percent95 = np.percentile(q_errors, 95)\n",
    "    percent99 = np.percentile(q_errors, 99)\n",
    "    median = np.median(q_errors)\n",
    "    maxi = np.max(q_errors)\n",
    "    print ('Testing: Mean Error {}, Median Error {}, 90 Percent {}, 95 Percent {}, 99 Percent {}, Max Percent {}'\n",
    "           .format(mean, median, percent90, percent95, percent99, maxi))\n",
    "    \n",
    "\n",
    "def train_and_test_baseline(mlp_model, threshold_model, output_model, opt, train, test, episode):\n",
    "    print ('size: {}'.format(len(train)))\n",
    "    test_errors = []\n",
    "    for e in range(episode):\n",
    "#         embed_model.train()\n",
    "        mlp_model.train()\n",
    "        threshold_model.train()\n",
    "        output_model.train()\n",
    "        for batch_idx, (masks, queries, thresholds, targets) in enumerate(train):\n",
    "#             print (e, batch_idx)\n",
    "#             print (queries.shape)\n",
    "    #         print (torch.cat((queries, thresholds), 1)[0])\n",
    "            queries = torch.FloatTensor(data_test[queries.type(torch.LongTensor)].astype(float) / normalize_factor)\n",
    "            queries = Variable(queries)\n",
    "            thresholds = Variable(thresholds)\n",
    "            targets = Variable(targets)\n",
    "    #         print (targets)\n",
    "            opt.zero_grad()\n",
    "#             queries = embed_model(queries, masks)\n",
    "#             print (queries.shape)\n",
    "            batch_size = queries.shape[0]\n",
    "            join_size = queries.shape[1]\n",
    "            queries = queries.view(batch_size * join_size, -1)\n",
    "#             print (queries.shape)\n",
    "            queries = mlp_model(queries)\n",
    "#             print (masks.shape)\n",
    "            queries = (queries.view(batch_size, join_size, -1) * masks).sum(dim=1) / 100.0\n",
    "#             queries = queries.view(queries.shape[0], -1)\n",
    "#             print (queries.shape)\n",
    "            threshold = threshold_model(thresholds)\n",
    "            estimates = output_model(queries, threshold)\n",
    "            \n",
    "            loss = l1_loss(estimates, targets)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "#             for p in model.parameters():\n",
    "#                 p.data.clamp_(-10, 10)\n",
    "            next(threshold_model.fc1.parameters()).data.clamp_(0)\n",
    "            next(threshold_model.fc2.parameters()).data.clamp_(0)\n",
    "#             next(output_model.fc1.parameters()).data.clamp_(0)\n",
    "            next(output_model.fc2.parameters()).data.clamp_(0)\n",
    "#             if batch_idx % 100 == 0:\n",
    "#                 print('Training: Iteration {0}, Batch {1}, Loss {2}'.format(e, batch_idx, loss.item()))\n",
    "#                 print(cnn_models[0].layer[0].weight.grad)\n",
    "        \n",
    "#         embed_model.eval()\n",
    "        mlp_model.eval()\n",
    "        threshold_model.eval()\n",
    "        output_model.eval()\n",
    "        test_loss = 0.0\n",
    "        mse_error = 0.0\n",
    "        q_mean = 0.0\n",
    "        q_max = 0.0\n",
    "        for batch_idx, (masks, queries, thresholds, targets) in enumerate(test):\n",
    "            queries = torch.FloatTensor(data_test[queries.type(torch.LongTensor)].astype(float) / normalize_factor)\n",
    "            queries = Variable(queries)\n",
    "            thresholds = Variable(thresholds)\n",
    "            targets = Variable(targets)\n",
    "#             queries = embed_model(queries, masks)\n",
    "            \n",
    "            batch_size = queries.shape[0]\n",
    "            join_size = queries.shape[1]\n",
    "            queries = queries.view(batch_size * join_size, -1)\n",
    "            queries = mlp_model(queries)\n",
    "            queries = (queries.view(batch_size, join_size, -1) * masks).sum(dim=1) / 100.0\n",
    "#             queries = queries.view(queries.shape[0], -1)\n",
    "            threshold = threshold_model(thresholds)\n",
    "            estimates = output_model(queries, threshold)\n",
    "            \n",
    "            loss = l1_loss(estimates, targets)\n",
    "            mse, qer_mean, qer_max = print_loss(estimates, targets)\n",
    "            test_loss += loss.item()\n",
    "            mse_error += mse.item()\n",
    "            q_mean += qer_mean\n",
    "            if qer_max > q_max:\n",
    "                q_max = qer_max\n",
    "        test_loss /= len(test)\n",
    "        mse_error /= len(test)\n",
    "        q_mean /= len(test)\n",
    "        test_errors.append(q_mean)\n",
    "        print ('Testing: Iteration {0}, Loss {1}, MSE_error {2}, Q_error_mean {3}, Q_error_max {4}'.format(e, test_loss, mse_error, q_mean, q_max))\n",
    "    return np.mean(test_errors[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sunji/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: Mean Error 4.417064832687378, Median Error 2.2970136404037476, 90 Percent 8.92913579940796, 95 Percent 16.272004032134994, 99 Percent 36.04088249206542, Max Percent 88.00776672363281\n",
      "Time used: 148.73562700000002\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sunji/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-7b950fda5937>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#     train_and_test_baseline(mlp_models[idx], threshold_models[idx], output_models[idx], opt, train, test, episode)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0monly_test_baseline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0melapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Time used:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0melapsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-5d191caffe81>\u001b[0m in \u001b[0;36monly_test_baseline\u001b[0;34m(mlp_model, threshold_model, output_model, test)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mq_errors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mqueries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnormalize_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mqueries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthresholds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# embed_models = [Set_CNN(queries_dimension) for _ in range(cluster_size)]\n",
    "import time\n",
    "# output_models = [Output_Model(hidden_num) for _ in range(cluster_size)]\n",
    "# mlp_models = [MLP_Model(queries_dimension) for _ in range(cluster_size)]\n",
    "# threshold_models = [Threshold_Model() for _ in range(cluster_size)]\n",
    "for idx in range(0, cluster_size):\n",
    "    print (idx)\n",
    "    test = test_loaders[idx]\n",
    "    train = train_loaders[idx]\n",
    "    paras = list()\n",
    "    paras += list(mlp_models[idx].parameters())\n",
    "    paras += list(threshold_models[idx].parameters())\n",
    "    paras += list(output_models[idx].parameters())\n",
    "    opt = optim.Adam(paras, lr=0.001)\n",
    "    episode = 5\n",
    "#     train_and_test_baseline(mlp_models[idx], threshold_models[idx], output_models[idx], opt, train, test, episode)\n",
    "    start = time.clock()\n",
    "    only_test_baseline(mlp_models[idx], threshold_models[idx], output_models[idx], test)\n",
    "    elapsed = (time.clock() - start)\n",
    "    print(\"Time used:\",elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gist_960_euclidean'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = [49.20472645759583, 88.7]\n",
    "mnist = [139.52747459362912, 156]\n",
    "nytimes = [78.05630527494333, 126]\n",
    "sift = [41.99033835162995, 96]\n",
    "kosarak = [2913.226723670959, 3760]\n",
    "gist = [117.46886035192537, 156]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# glove = [0.887, 1.754, 570, 610]\n",
    "# gist = [1.56, 2.28, 178, 198]\n",
    "# kosarak = [37.6, 72.5, 169, 188]\n",
    "# nytimes = [1.26, 2.67, 133, 154]\n",
    "# mnist = [1.56, 3.31, 14, 16]\n",
    "# sift = [0.96, 1.76, 133, 141]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "\n",
    "name_list = ['MNIST','GIST','GloVe','Kosarak','NYTimes', 'SIFT']\n",
    "num_list = [mnist[0], gist[0], glove[0], kosarak[0], nytimes[0], sift[0]]\n",
    "num_list1 = [mnist[1], gist[1], glove[1], kosarak[1], nytimes[1], sift[1]]\n",
    "# num_list2 = [mnist[2], gist[2], glove[2], kosarak[2], nytimes[2], sift[2]]\n",
    "# num_list3 = [mnist[3], gist[3], glove[3], kosarak[3], nytimes[3], sift[3]]\n",
    "# num_list3 = [mnist['glcnn'], gist['glcnn'], glove['glcnn'], kosarak['glcnn'], nytimes['glcnn'], sift['glcnn']]\n",
    "# num_list4 = [mnist['gl+'], gist['gl+'], glove['gl+'], kosarak['gl+'], nytimes['gl+'], sift['gl+']]\n",
    "# num_list5 = [mnist['mlp'], gist['mlp'], glove['mlp'], kosarak['mlp'], nytimes['mlp'], sift['mlp']]\n",
    "x=np.array(range(len(name_list)))\n",
    "fig = plt.figure(figsize=(10.0, 5.0))\n",
    "# plt.ylim(0,2000)\n",
    "\n",
    "_ = plt.xticks(x,name_list)\n",
    "# plt.xticks(name_list)\n",
    "# for i in range(len(x)):\n",
    "#     x[i] = x[i] + width/2\n",
    "total_width, n = 0.8, 2\n",
    "width = total_width / n\n",
    "x = x - (total_width - width) / 2\n",
    "plt.bar(x, num_list, width=width, label='GLJoin+',fc = 'dimgrey')\n",
    "plt.bar(x + width, num_list1, width=width, label='GL+',fc = 'cornflowerblue')\n",
    "# plt.bar(x + width * 2, num_list2, width=width, label='Sampling',fc = 'lightcoral')\n",
    "# plt.bar(x + width * 3, num_list3, width=width, label='Kernel-based',fc = 'tan')\n",
    "# plt.bar(x + width * 4, num_list4, width=width, label='GL+',fc = 'plum')\n",
    "\n",
    "plt.tick_params(axis='x', labelsize=20)\n",
    "plt.tick_params(axis='y', labelsize=20)\n",
    "plt.xlabel('Datasets', fontsize=25)\n",
    "plt.ylabel('Latency (ms)', fontsize=25)\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.legend(fontsize = 25)\n",
    "plt.savefig('join_latency.eps', format='eps', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
